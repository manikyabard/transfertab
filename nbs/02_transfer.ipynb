{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer\n",
    "> Contains methods for transferring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from fastcore.foundation import *\n",
    "from fastcore.dispatch import *\n",
    "from transfertab.utils import *\n",
    "from transfertab.extract import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create collections of Embedding layers, which will be used to test our transfer methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs1 = ((3, 10), (2, 8))\n",
    "emb_szs2 = ((2, 10), (2, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed1 = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs1])\n",
    "embed2 = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(3, 10)\n",
       "  (1): Embedding(2, 8)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create collections containing required metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newcatcols = (\"new_cat1\", \"new_cat2\")\n",
    "oldcatcols = (\"old_cat2\", \"old_cat3\")\n",
    "\n",
    "newcatdict = {\"new_cat1\" : [\"new_class1\", \"new_class2\", \"new_class3\"], \"new_cat2\" : [\"new_class1\", \"new_class2\"]}\n",
    "oldcatdict = {\"old_cat2\" : [\"a\", \"b\"], \"old_cat3\" : [\"A\", \"B\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "json_file_path = \"../data/jsons/metadict.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "     metadict = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`metadict` is a `Dict` with the keys as the classes in dest. model's data, and value is another `Dict` where `mapped_cat` corresponds to the class in src model's data, along with information about how the classes map from dest. data to src data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "metadict = {'new_cat1': {'mapped_cat': 'old_cat2',\n",
    "  'classes_info': {'new_class1': ['a', 'b'],\n",
    "   'new_class2': ['b'],\n",
    "   'new_class3': []}},\n",
    " 'new_cat2': {'mapped_cat': 'old_cat3',\n",
    "  'classes_info': {'new_class1': ['A'], 'new_class2': []}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_cat1': {'mapped_cat': 'old_cat2',\n",
       "  'classes_info': {'new_class1': ['a', 'b'],\n",
       "   'new_class2': ['b'],\n",
       "   'new_class3': []}},\n",
       " 'new_cat2': {'mapped_cat': 'old_cat3',\n",
       "  'classes_info': {'new_class1': ['A'], 'new_class2': []}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"old_cat1\": [1, 2, 3, 4, 5], \"old_cat2\": ['a', 'b', 'b', 'b', 'a'], \"old_cat3\": ['A', 'B', 'B', 'B', 'A']})\n",
    "cats = (\"old_cat2\", \"old_cat3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "embdict = extractembeds(embed2, df, transfercats=cats, allcats=cats, path=\"tempwtbson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embdict = extractembeds(embed2, df, transfercats=cats, allcats=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_metadict_skeleton(df: pd.DataFrame, *, catcols=None, path=None):\n",
    "    catdict = getcatdict(df, catcols)\n",
    "    metadict = {}\n",
    "    for (cat, classes) in catdict.items():\n",
    "        metadict[cat] = {'mapped_cat': '', 'classes_info': {clas: [] for clas in classes}}\n",
    "    if path != None:\n",
    "        with open(path, 'w') as fp:\n",
    "            json.dump(metadict, fp)\n",
    "    return metadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'old_cat2': {'mapped_cat': '', 'classes_info': {'a': [], 'b': []}},\n",
       " 'old_cat3': {'mapped_cat': '', 'classes_info': {'A': [], 'B': []}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metadict_skeleton(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def transferembeds_(\n",
    "        dest_embeds: nn.Module, \n",
    "        src_embeds: nn.Module,\n",
    "        /,\n",
    "        metatransfer,\n",
    "        transfer_cats,\n",
    "        *,\n",
    "        newcatcols, \n",
    "        oldcatcols, \n",
    "        oldcatdict, \n",
    "        newcatdict, \n",
    "        aggfn = partial(torch.mean, dim=0)):\n",
    "    '''\n",
    "        Transfers embeddings from `src_embeds` to `dest_embeds`, \n",
    "        with the help of collections containing various metadata.\n",
    "    '''\n",
    "    src_state_dict = L(src_embeds.state_dict().items())\n",
    "    dest_state_dict = L(dest_embeds.state_dict().items())\n",
    "    for newcat in transfer_cats:\n",
    "        newidx = newcatcols.index(newcat)\n",
    "        oldidx = oldcatcols.index(metatransfer[newcat][\"mapped_cat\"])\n",
    "        new_ps = torch.zeros(src_state_dict[oldidx][1].shape[1], 0)\n",
    "        for newclass in newcatdict[newcat]:\n",
    "            classidxs = L(oldcatdict[oldcatcols[oldidx]]).argwhere(lambda x: x in metatransfer[newcat][\"classes_info\"][newclass])\n",
    "            if len(classidxs) == 0:\n",
    "                classidxs =  list(range(len(oldcatdict[oldcatcols[oldidx]])))\n",
    "            ps = torch.unsqueeze(aggfn(torch.index_select(src_state_dict[oldidx][1], 0, torch.LongTensor(classidxs))), -1)\n",
    "            new_ps = torch.cat((new_ps, ps), dim=1)\n",
    "        dest_embeds.state_dict()[dest_state_dict[newidx][0]].copy_(new_ps.T)\n",
    "        \n",
    "@typedispatch\n",
    "def transferembeds_(\n",
    "        dest_embeds: nn.Module,\n",
    "        src_embeds: dict,\n",
    "        metatransfer,\n",
    "        transfer_cats,\n",
    "        *,\n",
    "        newcatcols, \n",
    "        newcatdict, \n",
    "        aggfn = partial(torch.mean, dim=0)):\n",
    "    dest_state_dict = L(dest_embeds.state_dict().items())\n",
    "    for newcat in transfer_cats:\n",
    "        newidx = newcatcols.index(newcat)\n",
    "        oldcatname = metatransfer[newcat]['mapped_cat']\n",
    "        new_ps = torch.zeros(torch.tensor(src_embeds[oldcatname]['embeddings']).shape[1], 0)\n",
    "        for newclass in newcatdict[newcat]:\n",
    "            classidxs = L(src_embeds[oldcatname]['classes']).argwhere(lambda x: x in metatransfer[newcat][\"classes_info\"][newclass])\n",
    "            if len(classidxs) == 0:\n",
    "                classidxs = list(range(len(src_embeds[oldcatname]['classes'])))\n",
    "            ps = torch.unsqueeze(aggfn(torch.index_select(torch.tensor(src_embeds[oldcatname]['embeddings']), 0, torch.LongTensor(classidxs))), -1)\n",
    "            new_ps = torch.cat((new_ps, ps), dim=1)\n",
    "        dest_embeds.state_dict()[dest_state_dict[newidx][0]].copy_(new_ps.T)\n",
    "            \n",
    "            \n",
    "@typedispatch\n",
    "def transferembeds_(\n",
    "        dest_embeds: nn.Module, \n",
    "        src_embeds: pathlib.PosixPath, \n",
    "        metatransfer,\n",
    "        transfer_cats,\n",
    "        *,\n",
    "        kind = \"bson\",\n",
    "        **kwargs):\n",
    "    if kind == \"json\":\n",
    "        with open(src_embeds, 'r') as fp:\n",
    "            src_embeds = json.loads(fp.read())\n",
    "    else:\n",
    "        src_embeds = load_bson(src_embeds)\n",
    "    transferembeds_(dest_embeds, src_embeds, metatransfer, transfer_cats, **kwargs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Module,Module) -> transferembeds_\n",
       "(Module,dict) -> transferembeds_\n",
       "(Module,PosixPath) -> transferembeds_\n",
       "(Module,str) -> transferembeds_"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skip\n",
    "transferembeds_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings before transfer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.5078,  1.1805, -0.7152, -0.2090, -0.3791, -0.3538,  2.0874, -1.2128,\n",
       "                        0.5305, -1.5456],\n",
       "                      [-0.6374,  0.5955, -0.6828, -0.3867, -0.1883,  0.6705,  0.0604,  1.2784,\n",
       "                       -0.0404,  0.5722],\n",
       "                      [-0.8835, -1.9918,  0.8149, -0.4123, -0.6302,  0.0977, -0.4842, -0.6732,\n",
       "                        1.2273, -0.4338]])),\n",
       "             ('1.weight',\n",
       "              tensor([[-0.2471, -1.1222,  1.2055,  0.5520, -0.4882, -0.3273, -0.7765,  0.4155],\n",
       "                      [ 0.2077,  0.5769, -0.1930, -0.9279, -1.0475, -3.3709, -0.9812, -0.5121]]))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skip\n",
    "embed1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.6536,  0.1894, -0.4986, -0.1123,  0.3157,  1.4084,  0.5261,  1.0641,\n",
       "                        0.5555, -2.8336],\n",
       "                      [ 0.1326, -1.0560,  1.3056,  0.5426,  0.7622,  1.3548, -1.6767, -0.1300,\n",
       "                        0.5395, -0.0292]])),\n",
       "             ('1.weight',\n",
       "              tensor([[-0.2570, -0.3869, -0.3253, -0.0735, -0.1460,  1.2832,  2.0547,  0.4501],\n",
       "                      [ 0.9373, -0.3996,  2.0042, -0.8417, -0.9869,  1.8711, -1.2488, -0.6895]]))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skip\n",
    "embed2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "transfer_cats = (\"new_cat1\", \"new_cat2\")\n",
    "transferembeds_(embed1, embdict, metadict, transfer_cats, newcatcols=newcatcols, oldcatcols=oldcatcols, newcatdict=newcatdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "transfer_cats = (\"new_cat1\", \"new_cat2\")\n",
    "transferembeds_(embed1, embed2, metadict, transfer_cats, newcatcols=newcatcols, oldcatcols=oldcatcols, oldcatdict=oldcatdict, newcatdict=newcatdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "#skip\n",
    "transfer_cats = (\"new_cat1\", \"new_cat2\")\n",
    "transferembeds_(embed1, pathlib.Path(\"tempwtbson\"), metadict, transfer_cats, newcatcols=newcatcols, oldcatcols=oldcatcols, newcatdict=newcatdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings after transfer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.2605, -0.4333,  0.4035,  0.2152,  0.5390,  1.3816, -0.5753,  0.4670,\n",
       "                        0.5475, -1.4314],\n",
       "                      [ 0.1326, -1.0560,  1.3056,  0.5426,  0.7622,  1.3548, -1.6767, -0.1300,\n",
       "                        0.5395, -0.0292],\n",
       "                      [-0.2605, -0.4333,  0.4035,  0.2152,  0.5390,  1.3816, -0.5753,  0.4670,\n",
       "                        0.5475, -1.4314]])),\n",
       "             ('1.weight',\n",
       "              tensor([[-0.2570, -0.3869, -0.3253, -0.0735, -0.1460,  1.2832,  2.0547,  0.4501],\n",
       "                      [ 0.3402, -0.3932,  0.8394, -0.4576, -0.5665,  1.5772,  0.4030, -0.1197]]))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skip\n",
    "embed1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.6536,  0.1894, -0.4986, -0.1123,  0.3157,  1.4084,  0.5261,  1.0641,\n",
       "                        0.5555, -2.8336],\n",
       "                      [ 0.1326, -1.0560,  1.3056,  0.5426,  0.7622,  1.3548, -1.6767, -0.1300,\n",
       "                        0.5395, -0.0292]])),\n",
       "             ('1.weight',\n",
       "              tensor([[-0.2570, -0.3869, -0.3253, -0.0735, -0.1460,  1.2832,  2.0547,  0.4501],\n",
       "                      [ 0.9373, -0.3996,  2.0042, -0.8417, -0.9869,  1.8711, -1.2488, -0.6895]]))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#skip\n",
    "embed2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip\n",
    "#hide\n",
    "# skip\n",
    "os.remove(\"tempwtbson\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#skip\n",
    "_all_ = ['transferembeds_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_utils.ipynb.\n",
      "Converted 01_extract.ipynb.\n",
      "Converted 02_transfer.ipynb.\n",
      "Converted 03_load_tests.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "#skip\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('fastenv': conda)",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
