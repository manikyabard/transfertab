{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transfertab\n",
    "\n",
    "> Allow transfer learning using structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from transfertab.utils import *\n",
    "from nbdev.showdoc import *\n",
    "from fastai.tabular.all import *\n",
    "from transfertab.transfer import *\n",
    "from transfertab.extract import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "pip install transfertab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TransferTab enables effective transfer learning from models trained on tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make use of `transfertab`, you'll need  \n",
    "\t* A pytorch model which contains some embeddings in a layer group.  \n",
    "\t* Another model to transfer these embeddings to, along with the metadata about the dataset on which this model will be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole process takes place in two main steps-  \n",
    "\t1. Extraction  \n",
    "\t2. Transfer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction\n",
    "This involves storing the embeddings present in the model to a `JSON` structure. This `JSON` would contain the embeddings related to the categorical variables, and can be later transfered to another model which can also benefit from these categories. It will also be possible to have multiple `JSON` files constructed from various models with different categorical variables and then use them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll quickly construct a `ModuleList` with a bunch of `Embedding` layers, and see how to transfer it's embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs1 = ((3, 10), (2, 8))\n",
    "emb_szs2 = ((2, 10), (2, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed1 = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs1])\n",
    "embed2 = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(3, 10)\n",
       "  (1): Embedding(2, 8)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the `extractembeds` function to extract the embeddings. Take a look at the documentation to see other dispatch methods, and details on the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"old_cat1\": [1, 2, 3, 4, 5], \"old_cat2\": ['a', 'b', 'b', 'b', 'a'], \"old_cat3\": ['A', 'B', 'B', 'B', 'A']})\n",
    "cats = (\"old_cat2\", \"old_cat3\")\n",
    "embdict = extractembeds(embed2, df, transfercats=cats, allcats=cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'old_cat2': {'classes': ['a', 'b'],\n",
       "  'embeddings': [[-0.28762340545654297,\n",
       "    -0.142189621925354,\n",
       "    0.2027226686477661,\n",
       "    1.1096185445785522,\n",
       "    -0.4540262520313263,\n",
       "    -1.346120834350586,\n",
       "    0.048871781677007675,\n",
       "    0.1740419715642929,\n",
       "    0.002095407573506236,\n",
       "    0.721653163433075],\n",
       "   [-0.9072648882865906,\n",
       "    2.674738645553589,\n",
       "    -0.8560850024223328,\n",
       "    -1.119917869567871,\n",
       "    -0.19618849456310272,\n",
       "    1.1431224346160889,\n",
       "    -0.5177133679389954,\n",
       "    -0.6497849822044373,\n",
       "    -0.9011525511741638,\n",
       "    0.9314191341400146]]},\n",
       " 'old_cat3': {'classes': ['A', 'B'],\n",
       "  'embeddings': [[2.5755045413970947,\n",
       "    -1.3670053482055664,\n",
       "    -0.3207620680332184,\n",
       "    -1.1824427843093872,\n",
       "    0.07631386071443558,\n",
       "    0.501422107219696,\n",
       "    0.8510317802429199,\n",
       "    -0.6687257289886475],\n",
       "   [-1.3658113479614258,\n",
       "    -0.27968257665634155,\n",
       "    0.26537612080574036,\n",
       "    0.36773681640625,\n",
       "    -0.9940593242645264,\n",
       "    0.9408144354820251,\n",
       "    0.5295664668083191,\n",
       "    -0.5038257241249084]]}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer\n",
    "The transfer process involves using the extracted weights, or a model directly and reusing trained paramters. We can define how this process will take place using the `metadict` which is a mapping of all the categories (in the current dataset), and contains information about the category it is mapped to (from the previous dataset which was used to train the old model), and how the new classes map to the old classes. We can even choose to map multiple classes to a single one, and in this case the `aggfn` parameter is used to aggregate the embedding vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"../data/jsons/metadict.json\"\n",
    "\n",
    "with open(json_file_path, 'r') as j:\n",
    "     metadict = json.loads(j.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'new_cat1': {'mapped_cat': 'old_cat2',\n",
       "  'classes_info': {'new_class1': ['a', 'b'],\n",
       "   'new_class2': ['b'],\n",
       "   'new_class3': []}},\n",
       " 'new_cat2': {'mapped_cat': 'old_cat3',\n",
       "  'classes_info': {'new_class1': ['A'], 'new_class2': []}}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the layer parameters before and after transferring to see if it worked as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.6940, -0.0337,  0.9491, -1.0520,  0.7804,  2.0246,  0.4242, -1.8351,\n",
       "                        0.4660,  1.7667],\n",
       "                      [-0.2802,  0.6081, -0.8459, -0.3288, -1.1264,  0.7621,  0.9347,  1.8096,\n",
       "                       -0.1998, -0.2541],\n",
       "                      [ 0.5706, -0.5213, -0.1398, -0.3742, -1.1951,  1.9640,  0.4132,  2.0365,\n",
       "                        0.0655,  0.5189]])),\n",
       "             ('1.weight',\n",
       "              tensor([[ 0.9506, -0.0057,  0.2754,  0.8276,  0.8675,  1.2238, -1.5603,  1.0301],\n",
       "                      [-0.7315, -0.3735,  0.6059,  0.2659, -0.4918,  1.5501,  0.0221, -0.6199]]))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-2.8762e-01, -1.4219e-01,  2.0272e-01,  1.1096e+00, -4.5403e-01,\n",
       "                       -1.3461e+00,  4.8872e-02,  1.7404e-01,  2.0954e-03,  7.2165e-01],\n",
       "                      [-9.0726e-01,  2.6747e+00, -8.5609e-01, -1.1199e+00, -1.9619e-01,\n",
       "                        1.1431e+00, -5.1771e-01, -6.4978e-01, -9.0115e-01,  9.3142e-01]])),\n",
       "             ('1.weight',\n",
       "              tensor([[ 2.5755, -1.3670, -0.3208, -1.1824,  0.0763,  0.5014,  0.8510, -0.6687],\n",
       "                      [-1.3658, -0.2797,  0.2654,  0.3677, -0.9941,  0.9408,  0.5296, -0.5038]]))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_cats = (\"new_cat1\", \"new_cat2\")\n",
    "newcatcols = (\"new_cat1\", \"new_cat2\")\n",
    "oldcatcols = (\"old_cat2\", \"old_cat3\")\n",
    "\n",
    "newcatdict = {\"new_cat1\" : [\"new_class1\", \"new_class2\", \"new_class3\"], \"new_cat2\" : [\"new_class1\", \"new_class2\"]}\n",
    "oldcatdict = {\"old_cat2\" : [\"a\", \"b\"], \"old_cat3\" : [\"A\", \"B\"]}\n",
    "\n",
    "transferembeds_(embed1, embdict, metadict, transfer_cats, newcatcols=newcatcols, oldcatcols=oldcatcols, newcatdict=newcatdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[-0.5974,  1.2663, -0.3267, -0.0051, -0.3251, -0.1015, -0.2344, -0.2379,\n",
       "                       -0.4495,  0.8265],\n",
       "                      [-0.9073,  2.6747, -0.8561, -1.1199, -0.1962,  1.1431, -0.5177, -0.6498,\n",
       "                       -0.9012,  0.9314],\n",
       "                      [-0.5974,  1.2663, -0.3267, -0.0051, -0.3251, -0.1015, -0.2344, -0.2379,\n",
       "                       -0.4495,  0.8265]])),\n",
       "             ('1.weight',\n",
       "              tensor([[ 2.5755, -1.3670, -0.3208, -1.1824,  0.0763,  0.5014,  0.8510, -0.6687],\n",
       "                      [ 0.6048, -0.8233, -0.0277, -0.4074, -0.4589,  0.7211,  0.6903, -0.5863]]))])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed1.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the embeddings have been transferred over."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
