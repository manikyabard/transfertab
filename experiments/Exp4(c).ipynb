{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "from transfertab.utils import *\n",
    "from transfertab.transfer import *\n",
    "from transfertab.extract import *\n",
    "from fastcore.xtras import *\n",
    "from fastai.learner import *\n",
    "import torch\n",
    "import numpy as np\n",
    "from fastai.interpret import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../data/bank-additional-full.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from fastai.callback.wandb import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28831.6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "41188 * 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA = df.iloc[0:28831]\n",
    "dfB = df.iloc[28831:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
       "       'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays',\n",
       "       'previous', 'poutcome', 'emp.var.rate', 'cons.price.idx',\n",
       "       'cons.conf.idx', 'euribor3m', 'nr.employed', 'y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contcols = ['age', 'duration', 'campaign', 'pdays',\n",
    "       'previous', 'emp.var.rate', 'cons.price.idx',\n",
    "       'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "catcols = ['job', 'marital', 'education', 'default', 'housing', 'loan','contact', \n",
    "\t'month', 'day_of_week','poutcome']\n",
    "target = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitsA = RandomSplitter(valid_pct=0.2)(range_of(dfA))\n",
    "toA = TabularPandas(dfA, procs=[Categorify, FillMissing, Normalize],\n",
    "                   cat_names=catcols,\n",
    "                   cont_names=contcols,\n",
    "                   y_names=target,\n",
    "                   splits=splitsA)\n",
    "dlsA = toA.dataloaders(bs=512)\n",
    "rocaucbin = RocAucBinary()\n",
    "learnA = tabular_learner(dlsA, metrics=[rocaucbin, accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmanikya\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">modelA training</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/transfertab/Experiments\" target=\"_blank\">https://wandb.ai/transfertab/Experiments</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/transfertab/Experiments/runs/1siad487\" target=\"_blank\">https://wandb.ai/transfertab/Experiments/runs/1siad487</a><br/>\n",
       "                Run data is saved locally in <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_083800-1siad487</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(1siad487)</h1><iframe src=\"https://wandb.ai/transfertab/Experiments/runs/1siad487\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff9f7d7b700>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='Experiments', \n",
    "    save_code=True, \n",
    "    group='Exp4c v2', \n",
    "    job_type='pretrain', \n",
    "    tags=['base', 'bank', 'modelA'], \n",
    "    name='modelA training',\n",
    "    notes=\"Training modelA from which we'll take embeddings\",\n",
    "    reinit=True,\n",
    "    dir='/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2',\n",
    "    entity='transfertab'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.742446</td>\n",
       "      <td>0.676085</td>\n",
       "      <td>0.901483</td>\n",
       "      <td>0.733611</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.721670</td>\n",
       "      <td>0.685274</td>\n",
       "      <td>0.940751</td>\n",
       "      <td>0.802116</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.700482</td>\n",
       "      <td>0.660726</td>\n",
       "      <td>0.936917</td>\n",
       "      <td>0.869754</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.671983</td>\n",
       "      <td>0.615222</td>\n",
       "      <td>0.950835</td>\n",
       "      <td>0.888831</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.625605</td>\n",
       "      <td>0.543329</td>\n",
       "      <td>0.952714</td>\n",
       "      <td>0.899063</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.546002</td>\n",
       "      <td>0.425536</td>\n",
       "      <td>0.925603</td>\n",
       "      <td>0.936178</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.422753</td>\n",
       "      <td>0.281234</td>\n",
       "      <td>0.918322</td>\n",
       "      <td>0.945023</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.302040</td>\n",
       "      <td>0.196519</td>\n",
       "      <td>0.888314</td>\n",
       "      <td>0.947451</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214999</td>\n",
       "      <td>0.146657</td>\n",
       "      <td>0.934127</td>\n",
       "      <td>0.947797</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.166288</td>\n",
       "      <td>0.127942</td>\n",
       "      <td>0.949302</td>\n",
       "      <td>0.947971</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.139979</td>\n",
       "      <td>0.138055</td>\n",
       "      <td>0.914386</td>\n",
       "      <td>0.947971</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.127579</td>\n",
       "      <td>0.123222</td>\n",
       "      <td>0.948124</td>\n",
       "      <td>0.946410</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.118868</td>\n",
       "      <td>0.126295</td>\n",
       "      <td>0.946335</td>\n",
       "      <td>0.946583</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.115920</td>\n",
       "      <td>0.123844</td>\n",
       "      <td>0.952062</td>\n",
       "      <td>0.946410</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.112042</td>\n",
       "      <td>0.119435</td>\n",
       "      <td>0.950642</td>\n",
       "      <td>0.948144</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.109102</td>\n",
       "      <td>0.124263</td>\n",
       "      <td>0.950407</td>\n",
       "      <td>0.945023</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.107584</td>\n",
       "      <td>0.124478</td>\n",
       "      <td>0.934363</td>\n",
       "      <td>0.949879</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.106787</td>\n",
       "      <td>0.123867</td>\n",
       "      <td>0.948302</td>\n",
       "      <td>0.945890</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.104831</td>\n",
       "      <td>0.120430</td>\n",
       "      <td>0.951225</td>\n",
       "      <td>0.947104</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.103177</td>\n",
       "      <td>0.120644</td>\n",
       "      <td>0.950658</td>\n",
       "      <td>0.947104</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.100989</td>\n",
       "      <td>0.121526</td>\n",
       "      <td>0.952069</td>\n",
       "      <td>0.947797</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.101278</td>\n",
       "      <td>0.120946</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>0.946410</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.100383</td>\n",
       "      <td>0.119791</td>\n",
       "      <td>0.952221</td>\n",
       "      <td>0.945023</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.098665</td>\n",
       "      <td>0.127096</td>\n",
       "      <td>0.948546</td>\n",
       "      <td>0.943115</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.125222</td>\n",
       "      <td>0.946060</td>\n",
       "      <td>0.948838</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.096316</td>\n",
       "      <td>0.123181</td>\n",
       "      <td>0.951687</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.094602</td>\n",
       "      <td>0.122731</td>\n",
       "      <td>0.949897</td>\n",
       "      <td>0.946757</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.092834</td>\n",
       "      <td>0.121625</td>\n",
       "      <td>0.952283</td>\n",
       "      <td>0.948318</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.091539</td>\n",
       "      <td>0.121895</td>\n",
       "      <td>0.952110</td>\n",
       "      <td>0.948318</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.090237</td>\n",
       "      <td>0.122350</td>\n",
       "      <td>0.951001</td>\n",
       "      <td>0.945196</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.089704</td>\n",
       "      <td>0.123925</td>\n",
       "      <td>0.951392</td>\n",
       "      <td>0.946757</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.088133</td>\n",
       "      <td>0.124658</td>\n",
       "      <td>0.949165</td>\n",
       "      <td>0.943115</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.087513</td>\n",
       "      <td>0.123645</td>\n",
       "      <td>0.950480</td>\n",
       "      <td>0.945369</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.086274</td>\n",
       "      <td>0.123924</td>\n",
       "      <td>0.950286</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.085311</td>\n",
       "      <td>0.123360</td>\n",
       "      <td>0.950858</td>\n",
       "      <td>0.947797</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.084526</td>\n",
       "      <td>0.125127</td>\n",
       "      <td>0.949607</td>\n",
       "      <td>0.946930</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.084070</td>\n",
       "      <td>0.126798</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.944676</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.082427</td>\n",
       "      <td>0.125071</td>\n",
       "      <td>0.948889</td>\n",
       "      <td>0.945890</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.080851</td>\n",
       "      <td>0.126445</td>\n",
       "      <td>0.948666</td>\n",
       "      <td>0.946583</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.080003</td>\n",
       "      <td>0.125524</td>\n",
       "      <td>0.950239</td>\n",
       "      <td>0.948491</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.079424</td>\n",
       "      <td>0.126035</td>\n",
       "      <td>0.949245</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.078750</td>\n",
       "      <td>0.126719</td>\n",
       "      <td>0.949070</td>\n",
       "      <td>0.945196</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.077940</td>\n",
       "      <td>0.126753</td>\n",
       "      <td>0.948758</td>\n",
       "      <td>0.946237</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.077487</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>0.949084</td>\n",
       "      <td>0.945716</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.077226</td>\n",
       "      <td>0.127044</td>\n",
       "      <td>0.949308</td>\n",
       "      <td>0.945196</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.077405</td>\n",
       "      <td>0.126853</td>\n",
       "      <td>0.949015</td>\n",
       "      <td>0.945196</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.076498</td>\n",
       "      <td>0.126920</td>\n",
       "      <td>0.949112</td>\n",
       "      <td>0.945716</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.076196</td>\n",
       "      <td>0.127092</td>\n",
       "      <td>0.948731</td>\n",
       "      <td>0.945369</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.075681</td>\n",
       "      <td>0.126865</td>\n",
       "      <td>0.948923</td>\n",
       "      <td>0.945890</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.075679</td>\n",
       "      <td>0.126972</td>\n",
       "      <td>0.948815</td>\n",
       "      <td>0.945369</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with valid_loss value: 0.6760854125022888.\n",
      "Better model found at epoch 2 with valid_loss value: 0.6607264280319214.\n",
      "Better model found at epoch 3 with valid_loss value: 0.6152218580245972.\n",
      "Better model found at epoch 4 with valid_loss value: 0.5433291792869568.\n",
      "Better model found at epoch 5 with valid_loss value: 0.42553603649139404.\n",
      "Better model found at epoch 6 with valid_loss value: 0.2812340259552002.\n",
      "Better model found at epoch 7 with valid_loss value: 0.19651906192302704.\n",
      "Better model found at epoch 8 with valid_loss value: 0.14665652811527252.\n",
      "Better model found at epoch 9 with valid_loss value: 0.1279415786266327.\n",
      "Better model found at epoch 11 with valid_loss value: 0.12322241067886353.\n",
      "Better model found at epoch 14 with valid_loss value: 0.1194349154829979.\n"
     ]
    }
   ],
   "source": [
    "cbs=[WandbCallback(log=\"all\", dataset_name=\"bank-additional-full (first .7)\", n_preds=128, seed=1), SaveModelCallback()]\n",
    "learnA.fit_one_cycle(50, cbs=cbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learnA.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learnA.model.state_dict(),\"../results/exp4c-v2/modelA_state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "catdictA = {col:list(learnA.dls.categorify.classes[col]) for col in catcols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = extractembeds(learnA.model, catdictA, transfercats=catcols, allcats=catcols, path=\"learnA_extracts\", kind=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 45710<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adde801e102a4026934c81ea72c44134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 2.40MB of 2.40MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_083800-1siad487/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_083800-1siad487/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>50</td></tr><tr><td>train_loss</td><td>0.07568</td></tr><tr><td>raw_loss</td><td>0.07273</td></tr><tr><td>wd_0</td><td>0.01</td></tr><tr><td>sqr_mom_0</td><td>0.99</td></tr><tr><td>lr_0</td><td>0.0</td></tr><tr><td>mom_0</td><td>0.95</td></tr><tr><td>eps_0</td><td>1e-05</td></tr><tr><td>_runtime</td><td>366</td></tr><tr><td>_timestamp</td><td>1635736447</td></tr><tr><td>_step</td><td>2249</td></tr><tr><td>valid_loss</td><td>0.12697</td></tr><tr><td>roc_auc_score</td><td>0.94882</td></tr><tr><td>accuracy</td><td>0.94537</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>███▇▆▅▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>███▇▅▄▃▂▁▁▁▁▁▂▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▂▃▄▅▆▇███████▇▇▇▇▆▆▆▆▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>██▇▆▅▄▃▂▁▁▁▁▁▁▁▂▂▂▂▃▃▃▃▄▄▅▅▅▆▆▆▇▇▇▇█████</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>valid_loss</td><td>███▇▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>roc_auc_score</td><td>▂▇▆█▅▄▁▆▄█▇██▆██████████████████████████</td></tr><tr><td>accuracy</td><td>▁▃▅▆████████████████████████████████████</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 51 media file(s), 18 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">modelA training</strong>: <a href=\"https://wandb.ai/transfertab/Experiments/runs/1siad487\" target=\"_blank\">https://wandb.ai/transfertab/Experiments/runs/1siad487</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitsB = RandomSplitter(valid_pct=0.2)(range_of(dfB))\n",
    "toB = TabularPandas(dfB, procs=[Categorify, FillMissing, Normalize],\n",
    "                   cat_names = catcols,\n",
    "                   cont_names = contcols,\n",
    "                   y_names=target,\n",
    "                   splits=splitsB)\n",
    "dlsB = toB.dataloaders(bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocaucbinB = RocAucBinary()\n",
    "learnB = tabular_learner(dlsB, metrics=[rocaucbinB, accuracy], emb_szs={'month':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catdict = getcatdict(df, catcols)\n",
    "# metadict = {}\n",
    "# for (cat, classes) in catdict.items():\n",
    "# \tmetadict[cat] = {'mapped_cat': cat, 'classes_info': {clas: clas for clas in classes}}\n",
    "# with open('bank_meta.json', 'w') as fp:\n",
    "# \tjson.dump(metadict, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadict={\"job\": {\"mapped_cat\": \"job\", \"classes_info\": {\"#na#\": \"#na#\", \"admin.\": \"admin.\", \"blue-collar\": \"blue-collar\", \"entrepreneur\": \"entrepreneur\", \"housemaid\": \"housemaid\", \"management\": \"management\", \"retired\": \"retired\", \"self-employed\": \"self-employed\", \"services\": \"services\", \"student\": \"student\", \"technician\": \"technician\", \"unemployed\": \"unemployed\", \"unknown\": \"unknown\"}}, \"marital\": {\"mapped_cat\": \"marital\", \"classes_info\": {\"#na#\": \"#na#\", \"divorced\": \"divorced\", \"married\": \"married\", \"single\": \"single\", \"unknown\": \"unknown\"}}, \"education\": {\"mapped_cat\": \"education\", \"classes_info\": {\"#na#\": \"#na#\", \"basic.4y\": \"basic.4y\", \"basic.6y\": \"basic.6y\", \"basic.9y\": \"basic.9y\", \"high.school\": \"high.school\", \"illiterate\": \"illiterate\", \"professional.course\": \"professional.course\", \"university.degree\": \"university.degree\", \"unknown\": \"unknown\"}}, \"default\": {\"mapped_cat\": \"default\", \"classes_info\": {\"#na#\": \"#na#\", \"no\": \"no\", \"unknown\": \"unknown\"}}, \"housing\": {\"mapped_cat\": \"housing\", \"classes_info\": {\"#na#\": \"#na#\", \"no\": \"no\", \"unknown\": \"unknown\", \"yes\": \"yes\"}}, \"loan\": {\"mapped_cat\": \"loan\", \"classes_info\": {\"#na#\": \"#na#\", \"no\": \"no\", \"unknown\": \"unknown\", \"yes\": \"yes\"}}, \"contact\": {\"mapped_cat\": \"contact\", \"classes_info\": {\"#na#\": \"#na#\", \"cellular\": \"cellular\", \"telephone\": \"telephone\"}}, \"month\": {\"mapped_cat\": \"month\", \"classes_info\": {\"#na#\": \"#na#\", \"apr\": \"apr\", \"aug\": \"aug\", \"dec\": \"dec\", \"jul\": \"jul\", \"jun\": \"jun\", \"mar\": \"mar\", \"may\": \"may\", \"nov\": \"nov\", \"oct\": \"oct\", \"sep\":[]}}, \"day_of_week\": {\"mapped_cat\": \"day_of_week\", \"classes_info\": {\"#na#\": \"#na#\", \"fri\": \"fri\", \"mon\": \"mon\", \"thu\": \"thu\", \"tue\": \"tue\", \"wed\": \"wed\"}}, \"poutcome\": {\"mapped_cat\": \"poutcome\", \"classes_info\": {\"#na#\": \"#na#\", \"failure\": \"failure\", \"nonexistent\": \"nonexistent\", \"success\": \"success\"}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/jsons/bank_meta.json', 'r') as fp:\n",
    "    metadict = json.load(fp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': {'mapped_cat': 'job',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'admin.': 'admin.',\n",
       "   'blue-collar': 'blue-collar',\n",
       "   'entrepreneur': 'entrepreneur',\n",
       "   'housemaid': 'housemaid',\n",
       "   'management': 'management',\n",
       "   'retired': 'retired',\n",
       "   'self-employed': 'self-employed',\n",
       "   'services': 'services',\n",
       "   'student': 'student',\n",
       "   'technician': 'technician',\n",
       "   'unemployed': 'unemployed',\n",
       "   'unknown': 'unknown'}},\n",
       " 'marital': {'mapped_cat': 'marital',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'divorced': 'divorced',\n",
       "   'married': 'married',\n",
       "   'single': 'single',\n",
       "   'unknown': 'unknown'}},\n",
       " 'education': {'mapped_cat': 'education',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'basic.4y': 'basic.4y',\n",
       "   'basic.6y': 'basic.6y',\n",
       "   'basic.9y': 'basic.9y',\n",
       "   'high.school': 'high.school',\n",
       "   'illiterate': 'illiterate',\n",
       "   'professional.course': 'professional.course',\n",
       "   'university.degree': 'university.degree',\n",
       "   'unknown': 'unknown'}},\n",
       " 'default': {'mapped_cat': 'default',\n",
       "  'classes_info': {'#na#': '#na#', 'no': 'no', 'unknown': 'unknown'}},\n",
       " 'housing': {'mapped_cat': 'housing',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'no': 'no',\n",
       "   'unknown': 'unknown',\n",
       "   'yes': 'yes'}},\n",
       " 'loan': {'mapped_cat': 'loan',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'no': 'no',\n",
       "   'unknown': 'unknown',\n",
       "   'yes': 'yes'}},\n",
       " 'contact': {'mapped_cat': 'contact',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'cellular': 'cellular',\n",
       "   'telephone': 'telephone'}},\n",
       " 'month': {'mapped_cat': 'month',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'apr': 'apr',\n",
       "   'aug': 'aug',\n",
       "   'dec': 'dec',\n",
       "   'jul': 'jul',\n",
       "   'jun': 'jun',\n",
       "   'mar': 'mar',\n",
       "   'may': 'may',\n",
       "   'nov': 'nov',\n",
       "   'oct': 'oct',\n",
       "   'sep': []}},\n",
       " 'day_of_week': {'mapped_cat': 'day_of_week',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'fri': 'fri',\n",
       "   'mon': 'mon',\n",
       "   'thu': 'thu',\n",
       "   'tue': 'tue',\n",
       "   'wed': 'wed'}},\n",
       " 'poutcome': {'mapped_cat': 'poutcome',\n",
       "  'classes_info': {'#na#': '#na#',\n",
       "   'failure': 'failure',\n",
       "   'nonexistent': 'nonexistent',\n",
       "   'success': 'success'}}}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#na#', 'no', 'unknown']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnB.dls.categorify['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#na#', 'no', 'unknown', 'yes']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnA.dls.categorify['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(13, 7)\n",
       "  (1): Embedding(5, 4)\n",
       "  (2): Embedding(9, 5)\n",
       "  (3): Embedding(4, 3)\n",
       "  (4): Embedding(4, 3)\n",
       "  (5): Embedding(4, 3)\n",
       "  (6): Embedding(3, 3)\n",
       "  (7): Embedding(10, 6)\n",
       "  (8): Embedding(6, 4)\n",
       "  (9): Embedding(4, 3)\n",
       ")"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnA.model.embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(13, 7)\n",
       "  (1): Embedding(5, 4)\n",
       "  (2): Embedding(9, 5)\n",
       "  (3): Embedding(3, 3)\n",
       "  (4): Embedding(4, 3)\n",
       "  (5): Embedding(4, 3)\n",
       "  (6): Embedding(3, 3)\n",
       "  (7): Embedding(11, 6)\n",
       "  (8): Embedding(6, 4)\n",
       "  (9): Embedding(4, 3)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnB.model.embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) ['job','marital','education','default','housing','loan','contact','month','day_of_week','poutcome']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnB.dls.cat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfercats = ['job',\n",
    " 'marital',\n",
    " 'education',\n",
    " 'default',\n",
    " 'housing',\n",
    " 'loan',\n",
    " 'contact',\n",
    " 'month',\n",
    " 'day_of_week',\n",
    " 'poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "catdictB = {col:list(learnB.dls.categorify.classes[col]) for col in catcols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_cats = (\" workclass\", \" marital_status\", \" race\", \" relationship\", \" education\")\n",
    "# catcolsB = tuple(learnB.dls.cat_names)\n",
    "# catdictB = {col:list(learnB.dls.categorify.classes[col]) for col in catcolsB}\n",
    "transferembeds_(\n",
    "    learnB.model.embeds, \n",
    "    learnA.model.embeds, \n",
    "    metadict, \n",
    "    transfercats, \n",
    "    newcatcols=catcols, \n",
    "    oldcatcols=catcols, \n",
    "    oldcatdict=catdictA, \n",
    "    newcatdict=catdictB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0041,  0.0100,  0.0102, -0.0024],\n",
       "        [ 0.0009,  0.0190,  0.0418,  0.0202],\n",
       "        [-0.0319,  0.0140, -0.0415, -0.0403],\n",
       "        [ 0.0654, -0.0346, -0.0149,  0.0547],\n",
       "        [-0.0699, -0.0018, -0.0980,  0.0875]], requires_grad=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnA.model.embeds[catcols.index('marital')].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0041,  0.0100,  0.0102, -0.0024],\n",
       "        [ 0.0009,  0.0190,  0.0418,  0.0202],\n",
       "        [-0.0319,  0.0140, -0.0415, -0.0403],\n",
       "        [ 0.0654, -0.0346, -0.0149,  0.0547],\n",
       "        [-0.0699, -0.0018, -0.0980,  0.0875]], requires_grad=True)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnB.model.embeds[catcols.index('marital')].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlsC = deepcopy(dlsB)\n",
    "rocaucbinC = RocAucBinary()\n",
    "learnC = tabular_learner(dlsC, metrics=[rocaucbinC, accuracy], emb_szs={'month':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnC.model.layers.load_state_dict(learnB.model.layers.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">modelB training</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/transfertab/Experiments\" target=\"_blank\">https://wandb.ai/transfertab/Experiments</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/transfertab/Experiments/runs/w8b916eb\" target=\"_blank\">https://wandb.ai/transfertab/Experiments/runs/w8b916eb</a><br/>\n",
       "                Run data is saved locally in <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_091156-w8b916eb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(w8b916eb)</h1><iframe src=\"https://wandb.ai/transfertab/Experiments/runs/w8b916eb\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ff9f9c2c910>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='Experiments',\n",
    "    entity='transfertab',\n",
    "    save_code=True, \n",
    "    group='Exp4c v2', \n",
    "    job_type='finetune', \n",
    "    tags=['transfer', 'bank', 'modelB'], \n",
    "    name='modelB training',\n",
    "    notes='Training modelB which contains transferred embeddings',\n",
    "    reinit=True,\n",
    "    dir='/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(catcols)):\n",
    "    learnB.model.embeds[i].weight.requires_grad = False\n",
    "learnB.create_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0012, -0.0142, -0.0104],\n",
       "        [-0.0150,  0.0564, -0.0425],\n",
       "        [-0.0274,  0.0058, -0.0065],\n",
       "        [ 0.0386, -0.0425,  0.0627]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnB.embeds[5].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback requires use of \"SaveModelCallback\" to log best model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.583056</td>\n",
       "      <td>0.652738</td>\n",
       "      <td>0.870181</td>\n",
       "      <td>0.725212</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.531010</td>\n",
       "      <td>0.522188</td>\n",
       "      <td>0.885025</td>\n",
       "      <td>0.811817</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.501736</td>\n",
       "      <td>0.498829</td>\n",
       "      <td>0.885407</td>\n",
       "      <td>0.809389</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbsB=[WandbCallback(log=\"all\", dataset_name=\"bank 0.3%\", n_preds=128, seed=1)]\n",
    "learnB.fit_one_cycle(3, cbs=cbsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(catcols)):\n",
    "    learnB.model.embeds[i].weight.requires_grad = True\n",
    "learnB.create_opt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.461604</td>\n",
       "      <td>0.481070</td>\n",
       "      <td>0.882981</td>\n",
       "      <td>0.804533</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.449091</td>\n",
       "      <td>0.459576</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>0.808580</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.429367</td>\n",
       "      <td>0.434223</td>\n",
       "      <td>0.885819</td>\n",
       "      <td>0.820316</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.409259</td>\n",
       "      <td>0.421703</td>\n",
       "      <td>0.887061</td>\n",
       "      <td>0.815864</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.394413</td>\n",
       "      <td>0.422471</td>\n",
       "      <td>0.887898</td>\n",
       "      <td>0.817887</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learnB.fit_one_cycle(5, cbs=cbsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learnB.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 46451<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32e582a1619449882c365447d49361e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.63MB of 0.63MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_091156-w8b916eb/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_091156-w8b916eb/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train_loss</td><td>0.39441</td></tr><tr><td>raw_loss</td><td>0.34937</td></tr><tr><td>wd_0</td><td>0.01</td></tr><tr><td>sqr_mom_0</td><td>0.99</td></tr><tr><td>lr_0</td><td>0.0</td></tr><tr><td>mom_0</td><td>0.94995</td></tr><tr><td>eps_0</td><td>1e-05</td></tr><tr><td>_runtime</td><td>115</td></tr><tr><td>_timestamp</td><td>1635738231</td></tr><tr><td>_step</td><td>152</td></tr><tr><td>valid_loss</td><td>0.42247</td></tr><tr><td>roc_auc_score</td><td>0.8879</td></tr><tr><td>accuracy</td><td>0.81789</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>██▇▇▆▆▅▅▅▅▄▄▄▄▄▂▂▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>██▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▄▃▃▂▄▄▃▃▂▂▂▂▃▂▂▁▁▁▂▂▁▂▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▂▅▇██▇▇▆▅▄▃▂▁▁▁▂▃▅▆█████▇▇▆▆▅▅▄▃▃▂▂▂▁▁▁</td></tr><tr><td>mom_0</td><td>█▇▅▂▁▁▂▂▃▄▅▆▇████▆▄▃▁▁▁▁▁▂▂▃▃▄▄▅▆▆▇▇▇███</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid_loss</td><td>█▄▃▃▂▁▁▁</td></tr><tr><td>roc_auc_score</td><td>▁▇▇▆▆▇██</td></tr><tr><td>accuracy</td><td>▁▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 7 W&B file(s), 8 media file(s), 8 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">modelB training</strong>: <a href=\"https://wandb.ai/transfertab/Experiments/runs/w8b916eb\" target=\"_blank\">https://wandb.ai/transfertab/Experiments/runs/w8b916eb</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.6 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.32<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">modelC training</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/transfertab/Experiments\" target=\"_blank\">https://wandb.ai/transfertab/Experiments</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/transfertab/Experiments/runs/2b8zxwxb\" target=\"_blank\">https://wandb.ai/transfertab/Experiments/runs/2b8zxwxb</a><br/>\n",
       "                Run data is saved locally in <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_091542-2b8zxwxb</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>Run(2b8zxwxb)</h1><iframe src=\"https://wandb.ai/transfertab/Experiments/runs/2b8zxwxb\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7ffa009f1730>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project='Experiments',\n",
    "    entity='transfertab',\n",
    "    save_code=True, \n",
    "    group='Exp4c v2', \n",
    "    job_type='controlgrp',\n",
    "    tags=['base', 'bank', 'modelC'], \n",
    "    name='modelC training',\n",
    "    notes='Training modelC which contains randomly initialized weights and same classifier weights as modelB',\n",
    "    reinit=True,\n",
    "    dir='/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandbCallback requires use of \"SaveModelCallback\" to log best model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.608667</td>\n",
       "      <td>0.660277</td>\n",
       "      <td>0.857243</td>\n",
       "      <td>0.683124</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.559486</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.879744</td>\n",
       "      <td>0.800081</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.520422</td>\n",
       "      <td>0.478313</td>\n",
       "      <td>0.886226</td>\n",
       "      <td>0.808175</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.488429</td>\n",
       "      <td>0.467712</td>\n",
       "      <td>0.879713</td>\n",
       "      <td>0.820720</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.460895</td>\n",
       "      <td>0.446551</td>\n",
       "      <td>0.882524</td>\n",
       "      <td>0.814245</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.437998</td>\n",
       "      <td>0.426298</td>\n",
       "      <td>0.890396</td>\n",
       "      <td>0.826386</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.419734</td>\n",
       "      <td>0.429554</td>\n",
       "      <td>0.888822</td>\n",
       "      <td>0.821125</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.406062</td>\n",
       "      <td>0.427293</td>\n",
       "      <td>0.889090</td>\n",
       "      <td>0.821934</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbsC=[WandbCallback(log=\"all\", dataset_name=\"bank 0.3%\", n_preds=128, seed=1)]\n",
    "learnC.fit_one_cycle(8, cbs=cbsC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learnC.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 46593<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018bd9b227294d9abd6fdd6a5fadfbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.63MB of 0.63MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_091542-2b8zxwxb/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/Users/manikyabardhan/Documents/github/transfertab/results/exp4c-v2/wandb/run-20211101_091542-2b8zxwxb/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>8</td></tr><tr><td>train_loss</td><td>0.40606</td></tr><tr><td>raw_loss</td><td>0.35641</td></tr><tr><td>wd_0</td><td>0.01</td></tr><tr><td>sqr_mom_0</td><td>0.99</td></tr><tr><td>lr_0</td><td>0.0</td></tr><tr><td>mom_0</td><td>0.94998</td></tr><tr><td>eps_0</td><td>1e-05</td></tr><tr><td>_runtime</td><td>67</td></tr><tr><td>_timestamp</td><td>1635738409</td></tr><tr><td>_step</td><td>151</td></tr><tr><td>valid_loss</td><td>0.42729</td></tr><tr><td>roc_auc_score</td><td>0.88909</td></tr><tr><td>accuracy</td><td>0.82193</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>███▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>raw_loss</td><td>██▇▆▆▆▆▅▄▄▅▄▄▄▃▄▂▃▃▃▂▃▂▄▂▂▂▃▂▂▂▂▁▂▂▁▂▂▂▁</td></tr><tr><td>wd_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>sqr_mom_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr_0</td><td>▁▁▂▃▄▅▆▇▇███████▇▇▇▆▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>mom_0</td><td>██▇▇▆▄▃▂▂▁▁▁▁▁▁▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇█████</td></tr><tr><td>eps_0</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid_loss</td><td>█▄▃▂▂▁▁▁</td></tr><tr><td>roc_auc_score</td><td>▁▆▇▆▆███</td></tr><tr><td>accuracy</td><td>▁▇▇█▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 7 W&B file(s), 8 media file(s), 8 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">modelC training</strong>: <a href=\"https://wandb.ai/transfertab/Experiments/runs/2b8zxwxb\" target=\"_blank\">https://wandb.ai/transfertab/Experiments/runs/2b8zxwxb</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learnB.model.state_dict(),\"../results/exp4c-v2/modelB_state_dict\")\n",
    "torch.save(learnC.model.state_dict(),\"../results/exp4c-v2/modelC_state_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embeds.0.weight',\n",
       "              tensor([[ 0.0028, -0.0037,  0.0106, -0.0079,  0.0066, -0.0125, -0.0009],\n",
       "                      [-0.0748, -0.0353, -0.0279, -0.0419,  0.0048,  0.1019,  0.0367],\n",
       "                      [ 0.0337,  0.0332, -0.0002,  0.0111,  0.0184,  0.0006,  0.0317],\n",
       "                      [ 0.0064,  0.0925,  0.0245,  0.0144, -0.0080, -0.0071, -0.0284],\n",
       "                      [ 0.0931, -0.0545,  0.1390, -0.0037, -0.0719, -0.0115, -0.0150],\n",
       "                      [-0.0386,  0.0412, -0.0634,  0.0064,  0.0619,  0.0253, -0.0042],\n",
       "                      [-0.0381, -0.0761, -0.0039, -0.0610,  0.0093, -0.0381,  0.0322],\n",
       "                      [ 0.0848, -0.0294,  0.0395,  0.0607, -0.0904, -0.0394,  0.1236],\n",
       "                      [ 0.0060,  0.0425, -0.0086,  0.0106,  0.0148,  0.0493, -0.0118],\n",
       "                      [-0.0169, -0.0866,  0.0317, -0.0122,  0.0251, -0.1155,  0.0106],\n",
       "                      [ 0.0598, -0.0023,  0.0174,  0.0342, -0.0088, -0.0320, -0.0730],\n",
       "                      [-0.0054,  0.0597, -0.0490,  0.0619, -0.0388, -0.0010, -0.0446],\n",
       "                      [-0.0346,  0.0329, -0.0559, -0.0779,  0.0905, -0.0121, -0.0039]])),\n",
       "             ('embeds.1.weight',\n",
       "              tensor([[-0.0041,  0.0100,  0.0102, -0.0024],\n",
       "                      [-0.0086,  0.0186,  0.0399,  0.0125],\n",
       "                      [-0.0404,  0.0170, -0.0541, -0.0395],\n",
       "                      [ 0.0666, -0.0388, -0.0164,  0.0740],\n",
       "                      [-0.0845,  0.0031, -0.1106,  0.0931]])),\n",
       "             ('embeds.2.weight',\n",
       "              tensor([[ 0.0059, -0.0020,  0.0019,  0.0061, -0.0048],\n",
       "                      [ 0.0597,  0.1177,  0.1186, -0.0544, -0.0423],\n",
       "                      [-0.0306, -0.0652, -0.0153,  0.0896,  0.0872],\n",
       "                      [ 0.0333, -0.0498,  0.0701,  0.0541,  0.0840],\n",
       "                      [ 0.0498, -0.0252,  0.0268, -0.0145,  0.0326],\n",
       "                      [ 0.0408,  0.0829,  0.0542, -0.0585, -0.0488],\n",
       "                      [-0.0106,  0.0246,  0.0162,  0.0361, -0.0629],\n",
       "                      [-0.0772, -0.0080, -0.0866, -0.0726, -0.0897],\n",
       "                      [-0.0504,  0.0272, -0.0656, -0.0539, -0.0377]])),\n",
       "             ('embeds.3.weight',\n",
       "              tensor([[-0.0060,  0.0189,  0.0150],\n",
       "                      [-0.0266,  0.0080, -0.0342],\n",
       "                      [ 0.0375, -0.0340,  0.0262]])),\n",
       "             ('embeds.4.weight',\n",
       "              tensor([[-0.0045, -0.0051, -0.0016],\n",
       "                      [-0.0336,  0.0686,  0.0328],\n",
       "                      [-0.0370,  0.0153, -0.0350],\n",
       "                      [ 0.0313, -0.0419,  0.0021]])),\n",
       "             ('embeds.5.weight',\n",
       "              tensor([[ 0.0012, -0.0142, -0.0104],\n",
       "                      [-0.0122,  0.0625, -0.0629],\n",
       "                      [-0.0230,  0.0030,  0.0085],\n",
       "                      [ 0.0296, -0.0451,  0.0757]])),\n",
       "             ('embeds.6.weight',\n",
       "              tensor([[-0.0063, -0.0112,  0.0176],\n",
       "                      [-0.1092,  0.0545,  0.0515],\n",
       "                      [ 0.0557, -0.0688, -0.0290]])),\n",
       "             ('embeds.7.weight',\n",
       "              tensor([[-0.0155, -0.0009,  0.0004,  0.0151, -0.0058, -0.0025],\n",
       "                      [ 0.0223,  0.0633,  0.0229, -0.0307,  0.0026,  0.0299],\n",
       "                      [-0.0039,  0.0270, -0.0022,  0.0147, -0.0322, -0.0180],\n",
       "                      [-0.0354,  0.0149, -0.0376,  0.0172, -0.0280, -0.0460],\n",
       "                      [ 0.0261, -0.0048, -0.0129, -0.0211,  0.0229,  0.0132],\n",
       "                      [ 0.0090, -0.0120,  0.0153,  0.0174, -0.0104,  0.0020],\n",
       "                      [-0.0413, -0.0589, -0.0229,  0.0614, -0.0211, -0.0338],\n",
       "                      [-0.0009, -0.0382,  0.0063,  0.0026,  0.0322,  0.0037],\n",
       "                      [ 0.0299,  0.0026,  0.0288, -0.0096,  0.0356,  0.0148],\n",
       "                      [-0.0495, -0.0637, -0.0111, -0.0077, -0.0158, -0.0494],\n",
       "                      [-0.0055, -0.0106, -0.0160,  0.0018, -0.0078, -0.0080]])),\n",
       "             ('embeds.8.weight',\n",
       "              tensor([[-0.0149,  0.0151,  0.0047, -0.0171],\n",
       "                      [ 0.0037, -0.0548,  0.0571,  0.0278],\n",
       "                      [ 0.0803, -0.0372, -0.0220, -0.0762],\n",
       "                      [-0.0623, -0.0635, -0.0729, -0.0186],\n",
       "                      [-0.0769,  0.0746, -0.0176, -0.0139],\n",
       "                      [ 0.0144,  0.0724,  0.0227,  0.0758]])),\n",
       "             ('embeds.9.weight',\n",
       "              tensor([[-0.0127,  0.0069,  0.0047],\n",
       "                      [-0.0297, -0.0343, -0.0328],\n",
       "                      [-0.0096,  0.0156,  0.0177],\n",
       "                      [ 0.0031,  0.0092,  0.0236]])),\n",
       "             ('bn_cont.weight',\n",
       "              tensor([0.9825, 1.0318, 0.9832, 0.9860, 0.9877, 0.9994, 1.0083, 0.9999, 1.0001,\n",
       "                      0.9885])),\n",
       "             ('bn_cont.bias',\n",
       "              tensor([ 0.0054, -0.0048,  0.0012,  0.0008, -0.0045, -0.0068,  0.0039, -0.0015,\n",
       "                       0.0104,  0.0004])),\n",
       "             ('bn_cont.running_mean',\n",
       "              tensor([-0.0049,  0.0029, -0.0003,  0.0116, -0.0047, -0.0034, -0.0041,  0.0005,\n",
       "                       0.0023,  0.0030])),\n",
       "             ('bn_cont.running_var',\n",
       "              tensor([0.9835, 1.0166, 0.9810, 0.9719, 0.9768, 1.0038, 0.9986, 0.9993, 0.9949,\n",
       "                      0.9965])),\n",
       "             ('bn_cont.num_batches_tracked', tensor(152)),\n",
       "             ('layers.0.0.weight',\n",
       "              tensor([[-0.1068, -0.1141, -0.0483,  ...,  0.0728, -0.1294, -0.0924],\n",
       "                      [ 0.1252,  0.1197,  0.0975,  ...,  0.0357,  0.1131, -0.0743],\n",
       "                      [-0.0123, -0.1159,  0.1176,  ..., -0.0701, -0.0165,  0.1237],\n",
       "                      ...,\n",
       "                      [-0.0033, -0.0789, -0.0378,  ...,  0.1134, -0.0643,  0.0293],\n",
       "                      [-0.0988, -0.0980,  0.0149,  ..., -0.1279,  0.0207,  0.0789],\n",
       "                      [-0.0916,  0.1009,  0.0628,  ..., -0.0855,  0.0501,  0.0959]])),\n",
       "             ('layers.0.2.weight',\n",
       "              tensor([1.0041, 1.0069, 1.0044, 1.0133, 1.0033, 0.9990, 1.0101, 1.0076, 0.9947,\n",
       "                      1.0084, 1.0060, 0.9933, 1.0021, 1.0031, 0.9957, 0.9971, 0.9916, 1.0002,\n",
       "                      1.0016, 1.0178, 0.9993, 0.9948, 0.9976, 1.0059, 0.9995, 1.0033, 0.9890,\n",
       "                      1.0157, 0.9867, 0.9982, 1.0019, 0.9944, 0.9880, 0.9985, 1.0033, 1.0016,\n",
       "                      0.9942, 1.0031, 0.9916, 1.0067, 0.9998, 1.0013, 0.9974, 1.0069, 0.9968,\n",
       "                      1.0025, 0.9988, 1.0047, 1.0053, 1.0057, 0.9950, 1.0076, 1.0025, 1.0186,\n",
       "                      1.0075, 0.9973, 0.9908, 0.9896, 0.9916, 1.0070, 0.9884, 0.9901, 1.0057,\n",
       "                      0.9953, 1.0101, 1.0009, 0.9998, 0.9909, 1.0087, 1.0011, 0.9935, 0.9973,\n",
       "                      0.9855, 1.0040, 1.0029, 0.9910, 1.0062, 0.9955, 0.9970, 1.0071, 0.9987,\n",
       "                      1.0001, 1.0007, 0.9908, 0.9948, 1.0048, 0.9955, 1.0159, 1.0006, 0.9940,\n",
       "                      1.0100, 1.0043, 1.0025, 0.9983, 1.0060, 0.9943, 0.9937, 1.0076, 1.0072,\n",
       "                      1.0032, 1.0037, 0.9946, 0.9885, 0.9959, 0.9931, 0.9972, 0.9984, 0.9993,\n",
       "                      0.9915, 0.9948, 0.9931, 1.0060, 0.9969, 1.0078, 1.0011, 0.9861, 0.9980,\n",
       "                      0.9978, 0.9923, 0.9868, 0.9878, 0.9900, 0.9961, 0.9966, 0.9991, 0.9967,\n",
       "                      1.0169, 1.0018, 0.9948, 0.9967, 1.0024, 1.0017, 1.0006, 0.9962, 1.0027,\n",
       "                      1.0120, 0.9994, 1.0154, 1.0052, 0.9979, 1.0045, 0.9952, 1.0038, 0.9967,\n",
       "                      1.0019, 1.0012, 1.0011, 1.0027, 0.9935, 0.9941, 0.9965, 0.9971, 0.9842,\n",
       "                      0.9979, 1.0040, 0.9964, 0.9985, 1.0072, 0.9996, 0.9939, 1.0042, 0.9989,\n",
       "                      1.0082, 1.0023, 1.0003, 1.0049, 0.9921, 1.0155, 0.9988, 0.9945, 0.9978,\n",
       "                      0.9994, 0.9979, 1.0029, 1.0128, 1.0086, 0.9929, 0.9904, 1.0059, 1.0062,\n",
       "                      0.9987, 0.9966, 0.9923, 0.9998, 1.0052, 1.0124, 0.9898, 0.9922, 0.9952,\n",
       "                      0.9919, 1.0166, 0.9937, 1.0073, 1.0022, 1.0105, 0.9991, 0.9926, 1.0043,\n",
       "                      0.9939, 0.9947])),\n",
       "             ('layers.0.2.bias',\n",
       "              tensor([ 1.0107e-02, -3.1756e-03,  5.0215e-03,  4.4318e-03, -3.4793e-03,\n",
       "                       1.4166e-02,  1.0424e-03,  6.5719e-04,  2.7506e-03,  7.9356e-03,\n",
       "                      -4.7556e-03,  1.1052e-02,  1.9234e-02, -6.2897e-03, -4.4675e-03,\n",
       "                       5.5105e-04,  1.3113e-02, -7.2500e-03,  9.2535e-03, -2.3095e-03,\n",
       "                       2.8025e-04,  9.5354e-03,  1.0862e-02,  6.0084e-03,  1.4006e-02,\n",
       "                       8.0452e-03,  4.0632e-03,  1.2438e-02, -3.8951e-03, -5.4387e-03,\n",
       "                      -6.6988e-03, -3.3343e-03,  8.5718e-04,  5.5667e-03,  1.6143e-03,\n",
       "                      -7.2255e-03,  3.7375e-03, -1.0232e-02,  6.4483e-03,  1.9977e-02,\n",
       "                       4.3182e-03, -5.7727e-03,  5.7899e-03, -1.0046e-02, -1.6110e-03,\n",
       "                      -3.8976e-03, -5.4606e-03, -2.7455e-03,  2.8077e-04,  6.2933e-03,\n",
       "                       3.6880e-03,  7.7149e-03,  9.1033e-03, -3.6931e-03, -5.3755e-03,\n",
       "                       9.5726e-03, -4.7684e-03,  8.7281e-03,  2.3368e-04,  5.6976e-03,\n",
       "                      -4.0385e-03,  5.7798e-03, -1.4119e-02,  9.6782e-03,  1.7753e-02,\n",
       "                      -5.0801e-03,  1.8610e-03, -1.1667e-02,  1.4153e-02,  5.9633e-03,\n",
       "                      -2.5407e-04, -3.9710e-03, -6.6521e-03,  6.6116e-03, -1.2207e-03,\n",
       "                       6.4035e-03, -1.1834e-02,  4.9320e-03,  1.0667e-02, -7.9134e-03,\n",
       "                      -4.6795e-03,  1.7348e-02,  1.1180e-03, -6.9486e-03,  5.5644e-03,\n",
       "                      -3.0038e-03, -3.7223e-03,  4.2797e-03,  4.6786e-03,  8.1853e-05,\n",
       "                       8.6254e-04, -5.5325e-03, -2.0785e-03,  4.0780e-03,  3.2447e-03,\n",
       "                      -4.8562e-03,  3.0159e-03, -4.4173e-03, -1.2544e-02, -6.0057e-03,\n",
       "                       3.1692e-03, -1.6961e-03, -5.0753e-03,  1.7347e-02,  5.4745e-03,\n",
       "                       8.5651e-03, -5.2650e-03, -8.3833e-03, -3.9509e-03, -5.1219e-03,\n",
       "                       1.8126e-03,  5.1422e-03, -5.5563e-03, -2.6653e-03,  3.8553e-03,\n",
       "                      -3.8194e-03,  1.9185e-03,  6.3589e-03, -2.3004e-03, -3.9305e-03,\n",
       "                       2.6487e-03, -1.5613e-03,  9.4370e-03, -2.6605e-03,  1.2526e-02,\n",
       "                       3.3447e-03, -2.8314e-03, -6.6922e-04,  4.7671e-03,  5.5726e-03,\n",
       "                       1.9369e-03, -1.4252e-02,  3.8053e-03,  8.1464e-03, -3.6768e-03,\n",
       "                       3.7360e-03,  6.2527e-03,  1.5486e-02, -1.1784e-02, -1.1715e-03,\n",
       "                      -4.0050e-03,  1.1454e-02, -2.7428e-03, -1.3782e-02,  6.6167e-03,\n",
       "                      -3.3025e-03,  3.9145e-03, -3.1851e-03, -5.9731e-03, -3.5068e-03,\n",
       "                       1.7276e-02, -5.8268e-03,  4.6648e-03,  4.8964e-03, -3.3834e-03,\n",
       "                      -1.7177e-02, -1.9484e-03,  2.3149e-03,  1.4932e-03, -2.2702e-03,\n",
       "                      -4.1657e-03,  1.2004e-02,  7.6631e-03,  4.4562e-03,  6.2241e-03,\n",
       "                       5.1040e-03, -5.3343e-03, -9.9993e-03, -1.6402e-03, -4.0909e-03,\n",
       "                      -5.2113e-03,  2.9176e-03,  1.1543e-02,  1.8469e-02,  3.0159e-03,\n",
       "                      -4.5405e-03, -1.7107e-03,  2.0308e-03,  1.5917e-02,  1.1113e-02,\n",
       "                       8.5368e-03, -3.6411e-03,  1.1119e-02,  2.2984e-03, -3.7161e-03,\n",
       "                      -3.1591e-03,  1.4740e-03,  8.4891e-04, -1.3174e-03,  1.6302e-04,\n",
       "                       9.9916e-03,  4.5332e-03, -9.7836e-03, -5.3799e-03, -1.1909e-02,\n",
       "                       7.8084e-03, -3.5872e-03,  3.4225e-03,  7.7373e-03,  1.3306e-02])),\n",
       "             ('layers.0.2.running_mean',\n",
       "              tensor([0.1510, 0.0685, 0.1384, 0.0627, 0.1362, 0.1032, 0.0985, 0.0996, 0.0785,\n",
       "                      0.0782, 0.0823, 0.1286, 0.0859, 0.0562, 0.0772, 0.0762, 0.1289, 0.0997,\n",
       "                      0.0935, 0.0933, 0.1426, 0.0367, 0.0718, 0.0479, 0.0718, 0.1461, 0.0915,\n",
       "                      0.0981, 0.0824, 0.1540, 0.0520, 0.1138, 0.1004, 0.0752, 0.0954, 0.0883,\n",
       "                      0.0836, 0.0919, 0.1042, 0.0650, 0.0774, 0.1405, 0.0797, 0.0654, 0.0759,\n",
       "                      0.1003, 0.1129, 0.1073, 0.0981, 0.0874, 0.0954, 0.1406, 0.0672, 0.0905,\n",
       "                      0.1093, 0.1601, 0.0928, 0.1066, 0.0727, 0.0989, 0.0804, 0.1288, 0.0683,\n",
       "                      0.0882, 0.0965, 0.0722, 0.1626, 0.1237, 0.0958, 0.1072, 0.1007, 0.0902,\n",
       "                      0.1284, 0.1619, 0.0853, 0.0828, 0.0408, 0.1266, 0.1270, 0.0691, 0.1030,\n",
       "                      0.1153, 0.0915, 0.0567, 0.1019, 0.0926, 0.0911, 0.0912, 0.1028, 0.0979,\n",
       "                      0.0563, 0.0822, 0.1010, 0.0855, 0.0532, 0.0969, 0.1002, 0.1009, 0.0693,\n",
       "                      0.0875, 0.0748, 0.1117, 0.1248, 0.1003, 0.1003, 0.0723, 0.0777, 0.1075,\n",
       "                      0.0807, 0.0952, 0.0828, 0.0772, 0.0648, 0.0962, 0.0708, 0.1678, 0.1004,\n",
       "                      0.1681, 0.0792, 0.1146, 0.1515, 0.1495, 0.1254, 0.0571, 0.0498, 0.1304,\n",
       "                      0.0734, 0.0764, 0.0953, 0.0969, 0.0729, 0.0869, 0.0699, 0.0611, 0.0668,\n",
       "                      0.1106, 0.0360, 0.0924, 0.1214, 0.1016, 0.0732, 0.0783, 0.0886, 0.0808,\n",
       "                      0.0615, 0.0753, 0.1023, 0.1180, 0.0317, 0.0948, 0.0792, 0.0871, 0.0869,\n",
       "                      0.1162, 0.1023, 0.0878, 0.0869, 0.0807, 0.0665, 0.1123, 0.0758, 0.1240,\n",
       "                      0.0760, 0.1065, 0.0957, 0.0892, 0.0771, 0.0721, 0.1187, 0.0773, 0.1250,\n",
       "                      0.0581, 0.0748, 0.0708, 0.0681, 0.0400, 0.0855, 0.0671, 0.0737, 0.0961,\n",
       "                      0.1051, 0.1354, 0.0895, 0.1167, 0.0847, 0.0713, 0.1440, 0.1020, 0.0985,\n",
       "                      0.1160, 0.0743, 0.0875, 0.0995, 0.0763, 0.1063, 0.1215, 0.1062, 0.1028,\n",
       "                      0.0953, 0.1422])),\n",
       "             ('layers.0.2.running_var',\n",
       "              tensor([0.0652, 0.0173, 0.0201, 0.0049, 0.0474, 0.0301, 0.0272, 0.0147, 0.0076,\n",
       "                      0.0164, 0.0197, 0.0516, 0.0257, 0.0106, 0.0214, 0.0202, 0.0204, 0.0312,\n",
       "                      0.0226, 0.0188, 0.0194, 0.0040, 0.0177, 0.0038, 0.0091, 0.0360, 0.0143,\n",
       "                      0.0161, 0.0131, 0.0599, 0.0095, 0.0348, 0.0268, 0.0203, 0.0146, 0.0295,\n",
       "                      0.0143, 0.0213, 0.0197, 0.0116, 0.0153, 0.0617, 0.0142, 0.0117, 0.0265,\n",
       "                      0.0249, 0.0503, 0.0245, 0.0267, 0.0248, 0.0167, 0.0234, 0.0095, 0.0242,\n",
       "                      0.0173, 0.0597, 0.0198, 0.0332, 0.0159, 0.0285, 0.0139, 0.0621, 0.0124,\n",
       "                      0.0204, 0.0108, 0.0148, 0.0299, 0.0401, 0.0259, 0.0254, 0.0242, 0.0266,\n",
       "                      0.0176, 0.0526, 0.0206, 0.0114, 0.0034, 0.0527, 0.0227, 0.0099, 0.0314,\n",
       "                      0.0448, 0.0196, 0.0140, 0.0157, 0.0320, 0.0140, 0.0208, 0.0326, 0.0372,\n",
       "                      0.0084, 0.0307, 0.0303, 0.0299, 0.0109, 0.0295, 0.0226, 0.0209, 0.0087,\n",
       "                      0.0273, 0.0138, 0.0517, 0.0625, 0.0256, 0.0259, 0.0179, 0.0186, 0.0315,\n",
       "                      0.0158, 0.0247, 0.0201, 0.0198, 0.0097, 0.0116, 0.0179, 0.0896, 0.0361,\n",
       "                      0.0289, 0.0169, 0.0149, 0.0243, 0.0283, 0.0551, 0.0074, 0.0047, 0.0195,\n",
       "                      0.0123, 0.0191, 0.0234, 0.0089, 0.0182, 0.0289, 0.0124, 0.0077, 0.0083,\n",
       "                      0.0516, 0.0031, 0.0121, 0.0298, 0.0227, 0.0197, 0.0120, 0.0282, 0.0210,\n",
       "                      0.0148, 0.0144, 0.0116, 0.0374, 0.0021, 0.0198, 0.0114, 0.0238, 0.0186,\n",
       "                      0.0344, 0.0104, 0.0266, 0.0323, 0.0180, 0.0135, 0.0240, 0.0047, 0.0149,\n",
       "                      0.0152, 0.0187, 0.0224, 0.0233, 0.0192, 0.0164, 0.0227, 0.0080, 0.0447,\n",
       "                      0.0126, 0.0094, 0.0063, 0.0140, 0.0026, 0.0212, 0.0116, 0.0160, 0.0116,\n",
       "                      0.0194, 0.0181, 0.0220, 0.0427, 0.0202, 0.0112, 0.0216, 0.0278, 0.0096,\n",
       "                      0.0600, 0.0115, 0.0250, 0.0259, 0.0079, 0.0327, 0.0397, 0.0184, 0.0298,\n",
       "                      0.0113, 0.0229])),\n",
       "             ('layers.0.2.num_batches_tracked', tensor(152)),\n",
       "             ('layers.1.0.weight',\n",
       "              tensor([[ 0.0504,  0.0461,  0.0567,  ..., -0.0267,  0.0372, -0.0263],\n",
       "                      [-0.0264, -0.0224, -0.0453,  ..., -0.0671, -0.0003, -0.0649],\n",
       "                      [-0.0216,  0.0476,  0.0057,  ...,  0.0529, -0.0612,  0.0502],\n",
       "                      ...,\n",
       "                      [-0.0277,  0.0432, -0.0510,  ...,  0.0249,  0.0413,  0.0266],\n",
       "                      [-0.0248,  0.0389,  0.0396,  ...,  0.0440, -0.0465, -0.0213],\n",
       "                      [ 0.0563,  0.0705,  0.0210,  ...,  0.0083,  0.0516, -0.0198]])),\n",
       "             ('layers.1.2.weight',\n",
       "              tensor([0.9946, 1.0045, 0.9975, 0.9958, 1.0015, 0.9945, 0.9912, 1.0022, 0.9904,\n",
       "                      0.9892, 0.9955, 1.0031, 0.9980, 0.9965, 0.9962, 0.9915, 0.9969, 0.9959,\n",
       "                      1.0031, 0.9962, 1.0074, 0.9941, 0.9953, 1.0023, 1.0072, 0.9964, 0.9971,\n",
       "                      0.9920, 0.9968, 1.0022, 0.9854, 0.9904, 0.9966, 0.9978, 0.9945, 0.9973,\n",
       "                      1.0011, 0.9951, 0.9922, 1.0005, 0.9886, 0.9972, 0.9984, 0.9936, 0.9944,\n",
       "                      1.0057, 0.9974, 1.0025, 0.9911, 0.9938, 0.9933, 1.0024, 0.9878, 1.0057,\n",
       "                      0.9972, 1.0048, 0.9930, 0.9956, 1.0002, 0.9843, 0.9890, 0.9973, 1.0086,\n",
       "                      0.9928, 0.9941, 0.9884, 0.9939, 0.9989, 0.9974, 1.0035, 1.0032, 0.9919,\n",
       "                      0.9901, 0.9962, 0.9982, 0.9972, 0.9918, 1.0023, 0.9989, 0.9816, 1.0056,\n",
       "                      0.9988, 1.0074, 0.9979, 0.9951, 1.0075, 0.9955, 0.9919, 0.9954, 0.9866,\n",
       "                      0.9985, 1.0010, 0.9972, 0.9932, 1.0001, 0.9946, 0.9935, 1.0038, 0.9902,\n",
       "                      0.9990])),\n",
       "             ('layers.1.2.bias',\n",
       "              tensor([-0.0641,  0.0691, -0.0703,  0.0714, -0.0664, -0.0667,  0.0701,  0.0696,\n",
       "                       0.0706, -0.0659,  0.0763, -0.0670,  0.0686, -0.0674,  0.0682, -0.0656,\n",
       "                       0.0699,  0.0683,  0.0822,  0.0684, -0.0677, -0.0673,  0.0699, -0.0662,\n",
       "                      -0.0670,  0.0745,  0.0695, -0.0660,  0.0753, -0.0675,  0.0486, -0.0665,\n",
       "                       0.0700, -0.0755,  0.0680, -0.0669,  0.0711, -0.0784, -0.0659,  0.0687,\n",
       "                       0.0685,  0.0699,  0.0690,  0.0700,  0.0800, -0.0701,  0.0686,  0.0805,\n",
       "                       0.0686,  0.0679, -0.0665,  0.0698,  0.0676, -0.0707,  0.0681, -0.0689,\n",
       "                       0.0681,  0.0847,  0.0697, -0.0649,  0.0690,  0.0700,  0.0714,  0.0683,\n",
       "                      -0.0675,  0.0678, -0.0663,  0.0698, -0.0673,  0.0685, -0.0779,  0.0746,\n",
       "                       0.0676, -0.0660,  0.0685,  0.0705,  0.0716, -0.0732,  0.0699,  0.0570,\n",
       "                      -0.0679, -0.0685, -0.0709,  0.0698,  0.0764, -0.0698,  0.0760,  0.0757,\n",
       "                      -0.0663,  0.0672,  0.0804, -0.0680, -0.0663, -0.0656,  0.0694, -0.0698,\n",
       "                       0.0765,  0.0769, -0.0767, -0.0661])),\n",
       "             ('layers.1.2.running_mean',\n",
       "              tensor([0.2148, 0.1575, 0.3132, 0.4007, 0.2144, 0.2968, 0.2248, 0.2158, 0.2904,\n",
       "                      0.2812, 0.2567, 0.1724, 0.4242, 0.2426, 0.2749, 0.2009, 0.2408, 0.2985,\n",
       "                      0.1735, 0.2336, 0.2418, 0.3184, 0.2573, 0.1775, 0.3150, 0.4750, 0.3141,\n",
       "                      0.3198, 0.3417, 0.2196, 0.2018, 0.2133, 0.2374, 0.2640, 0.2908, 0.2780,\n",
       "                      0.2440, 0.3778, 0.3584, 0.4452, 0.2800, 0.2947, 0.2640, 0.3608, 0.2043,\n",
       "                      0.2028, 0.3793, 0.2892, 0.3242, 0.2406, 0.2536, 0.4031, 0.3704, 0.2049,\n",
       "                      0.3310, 0.2888, 0.2850, 0.3909, 0.2279, 0.2141, 0.1916, 0.2951, 0.2027,\n",
       "                      0.1470, 0.3593, 0.2913, 0.2232, 0.2094, 0.3018, 0.2311, 0.1933, 0.2850,\n",
       "                      0.2861, 0.2394, 0.1808, 0.2487, 0.2089, 0.2573, 0.2223, 0.2278, 0.1937,\n",
       "                      0.1779, 0.1280, 0.4897, 0.2536, 0.2003, 0.4828, 0.2110, 0.2102, 0.3378,\n",
       "                      0.3214, 0.2415, 0.2353, 0.3319, 0.2790, 0.2819, 0.3080, 0.2929, 0.3945,\n",
       "                      0.1841])),\n",
       "             ('layers.1.2.running_var',\n",
       "              tensor([0.1020, 0.0409, 0.3939, 0.1734, 0.1575, 0.2864, 0.0782, 0.0930, 0.1223,\n",
       "                      0.1961, 0.1386, 0.0947, 0.1453, 0.1281, 0.2684, 0.1006, 0.2381, 0.2949,\n",
       "                      0.0876, 0.1078, 0.1508, 0.3060, 0.1460, 0.0967, 0.3012, 0.2431, 0.3341,\n",
       "                      0.3293, 0.1453, 0.1423, 0.1187, 0.1483, 0.1868, 0.1090, 0.1098, 0.1833,\n",
       "                      0.1521, 0.4357, 0.3294, 0.4571, 0.1128, 0.2273, 0.1817, 0.3454, 0.0642,\n",
       "                      0.1037, 0.3539, 0.2448, 0.2573, 0.1837, 0.1685, 0.1458, 0.1301, 0.0713,\n",
       "                      0.1219, 0.1966, 0.1929, 0.4350, 0.0970, 0.1439, 0.1192, 0.1210, 0.0615,\n",
       "                      0.0939, 0.2205, 0.1154, 0.1232, 0.0991, 0.2504, 0.1825, 0.1235, 0.1306,\n",
       "                      0.1541, 0.1726, 0.0707, 0.1762, 0.0666, 0.1683, 0.1464, 0.1914, 0.1318,\n",
       "                      0.0976, 0.0353, 0.2067, 0.2032, 0.0895, 0.2695, 0.0873, 0.1392, 0.3640,\n",
       "                      0.1392, 0.2092, 0.1470, 0.4660, 0.1231, 0.1644, 0.1758, 0.1649, 0.4325,\n",
       "                      0.1154])),\n",
       "             ('layers.1.2.num_batches_tracked', tensor(152)),\n",
       "             ('layers.2.0.weight',\n",
       "              tensor([[-0.0518,  0.0969, -0.0016,  0.0790, -0.1086, -0.0853, -0.0472, -0.0026,\n",
       "                        0.0373, -0.0878,  0.0355, -0.1042,  0.0418, -0.0006,  0.1049, -0.0888,\n",
       "                        0.1115,  0.0404,  0.0809,  0.1046, -0.1073,  0.0138,  0.0090, -0.0996,\n",
       "                       -0.1050,  0.1116,  0.0978, -0.0220,  0.0559, -0.0782, -0.0508,  0.0178,\n",
       "                        0.0473, -0.0939,  0.0974, -0.0220,  0.0520, -0.0756, -0.0273,  0.0686,\n",
       "                        0.0387, -0.0110,  0.0366,  0.1021,  0.0158, -0.1009,  0.0409,  0.0527,\n",
       "                        0.0962,  0.0645, -0.0038,  0.1132,  0.0868, -0.0582,  0.1073,  0.0213,\n",
       "                        0.0314, -0.0580,  0.0098, -0.0708, -0.0358,  0.0750, -0.0073,  0.0757,\n",
       "                       -0.0939,  0.1078, -0.1020,  0.0884, -0.0505,  0.1077,  0.0285,  0.0045,\n",
       "                        0.0785, -0.0706,  0.1117,  0.0565,  0.1083,  0.0592,  0.0704, -0.0831,\n",
       "                       -0.1021, -0.0277, -0.0057,  0.0781,  0.0793, -0.0197, -0.0019, -0.0372,\n",
       "                       -0.0820,  0.0974,  0.0593, -0.0149, -0.0942, -0.0782,  0.0212, -0.0254,\n",
       "                        0.0409,  0.0408,  0.0642, -0.0909],\n",
       "                      [-0.0158, -0.0611,  0.0473,  0.0407,  0.0331,  0.0197, -0.1018, -0.1128,\n",
       "                       -0.0073, -0.0135, -0.0079,  0.0365, -0.0994,  0.0766, -0.0381,  0.0903,\n",
       "                        0.0263, -0.1053,  0.0333,  0.0288,  0.0349,  0.0828, -0.0818,  0.0897,\n",
       "                        0.0652,  0.0670,  0.0207,  0.0730,  0.0103,  0.0333, -0.0627,  0.0676,\n",
       "                       -0.0174, -0.0577, -0.1027,  0.0985, -0.0137, -0.0435,  0.0689, -0.0650,\n",
       "                       -0.0746, -0.0789, -0.0684,  0.0629, -0.0260, -0.0254, -0.0722,  0.0037,\n",
       "                        0.0297, -0.0874,  0.0935,  0.0052, -0.0887,  0.0090, -0.0585,  0.1083,\n",
       "                       -0.1030, -0.0965, -0.0929,  0.0819, -0.0670, -0.0102, -0.1122, -0.0391,\n",
       "                       -0.0160, -0.0101, -0.0150, -0.0194,  0.0469, -0.0985,  0.0782, -0.0343,\n",
       "                       -0.0777,  0.0905, -0.0487, -0.0133,  0.0518,  0.1089, -0.0214, -0.0899,\n",
       "                        0.0168,  0.0453,  0.0701, -0.0015,  0.0488,  0.0705, -0.0394, -0.0726,\n",
       "                        0.0656, -0.0806,  0.0149,  0.0814,  0.0501,  0.1023, -0.0900,  0.0190,\n",
       "                        0.0101, -0.0116,  0.0891,  0.1113]])),\n",
       "             ('layers.2.0.bias', tensor([ 0.1311, -0.0081]))])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnB.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embeds.0.weight',\n",
       "              tensor([[-0.0020, -0.0050, -0.0009,  0.0097, -0.0045, -0.0065,  0.0064],\n",
       "                      [-0.0126, -0.0143,  0.0184, -0.0268,  0.0166,  0.0199, -0.0203],\n",
       "                      [ 0.0253,  0.0199, -0.0130,  0.0154, -0.0054,  0.0262,  0.0028],\n",
       "                      [-0.0205, -0.0126, -0.0010, -0.0073, -0.0068, -0.0157,  0.0137],\n",
       "                      [-0.0293, -0.0056,  0.0032, -0.0134,  0.0119, -0.0157, -0.0048],\n",
       "                      [ 0.0328,  0.0149, -0.0210, -0.0082, -0.0009,  0.0093,  0.0015],\n",
       "                      [-0.0201,  0.0226, -0.0007, -0.0049, -0.0081,  0.0021, -0.0120],\n",
       "                      [ 0.0216,  0.0103, -0.0190,  0.0204,  0.0037, -0.0207, -0.0171],\n",
       "                      [ 0.0220, -0.0270, -0.0241, -0.0035, -0.0119,  0.0320, -0.0027],\n",
       "                      [-0.0072,  0.0082,  0.0130, -0.0012, -0.0106, -0.0186,  0.0101],\n",
       "                      [ 0.0078,  0.0171,  0.0352,  0.0367,  0.0096, -0.0509,  0.0156],\n",
       "                      [ 0.0005, -0.0016,  0.0049,  0.0025,  0.0120,  0.0121,  0.0057],\n",
       "                      [ 0.0105,  0.0302, -0.0091,  0.0061, -0.0196,  0.0255,  0.0150]])),\n",
       "             ('embeds.1.weight',\n",
       "              tensor([[-0.0016, -0.0077, -0.0051, -0.0082],\n",
       "                      [-0.0094, -0.0074, -0.0200, -0.0050],\n",
       "                      [ 0.0118, -0.0014, -0.0125,  0.0106],\n",
       "                      [-0.0134, -0.0027, -0.0145,  0.0080],\n",
       "                      [-0.0090, -0.0150, -0.0210,  0.0264]])),\n",
       "             ('embeds.2.weight',\n",
       "              tensor([[-0.0119, -0.0062,  0.0083, -0.0134,  0.0114],\n",
       "                      [ 0.0271, -0.0078,  0.0144,  0.0294, -0.0181],\n",
       "                      [-0.0026,  0.0028, -0.0071, -0.0033,  0.0030],\n",
       "                      [ 0.0420,  0.0050, -0.0434,  0.0240, -0.0160],\n",
       "                      [ 0.0261,  0.0096, -0.0132,  0.0217, -0.0135],\n",
       "                      [ 0.0123,  0.0196,  0.0079,  0.0141, -0.0013],\n",
       "                      [-0.0235,  0.0072,  0.0126,  0.0037, -0.0202],\n",
       "                      [-0.0361, -0.0191,  0.0087, -0.0305,  0.0202],\n",
       "                      [-0.0095, -0.0003,  0.0109, -0.0026, -0.0127]])),\n",
       "             ('embeds.3.weight',\n",
       "              tensor([[ 0.0053,  0.0064,  0.0034],\n",
       "                      [ 0.0168,  0.0166, -0.0185],\n",
       "                      [ 0.0549, -0.0693,  0.0366]])),\n",
       "             ('embeds.4.weight',\n",
       "              tensor([[-0.0123,  0.0065,  0.0055],\n",
       "                      [ 0.0309, -0.0171, -0.0107],\n",
       "                      [-0.0024,  0.0335,  0.0341],\n",
       "                      [ 0.0089,  0.0002,  0.0161]])),\n",
       "             ('embeds.5.weight',\n",
       "              tensor([[-0.0014, -0.0033, -0.0053],\n",
       "                      [ 0.0217, -0.0042, -0.0260],\n",
       "                      [-0.0088,  0.0002,  0.0115],\n",
       "                      [-0.0561, -0.0276,  0.0099]])),\n",
       "             ('embeds.6.weight',\n",
       "              tensor([[ 0.0068,  0.0064,  0.0110],\n",
       "                      [-0.0088,  0.0128, -0.0180],\n",
       "                      [-0.0105, -0.0265,  0.0347]])),\n",
       "             ('embeds.7.weight',\n",
       "              tensor([[-0.0115,  0.0015,  0.0105, -0.0078,  0.0122,  0.0044],\n",
       "                      [ 0.0186,  0.0045, -0.0326, -0.0406,  0.0066,  0.0291],\n",
       "                      [ 0.0069,  0.0050,  0.0210,  0.0011, -0.0177,  0.0027],\n",
       "                      [-0.0066, -0.0060,  0.0064, -0.0162,  0.0135, -0.0043],\n",
       "                      [ 0.0143, -0.0158, -0.0155, -0.0078,  0.0102,  0.0322],\n",
       "                      [-0.0166,  0.0006,  0.0054,  0.0311, -0.0113, -0.0160],\n",
       "                      [ 0.0110, -0.0079,  0.0050,  0.0146,  0.0185, -0.0158],\n",
       "                      [ 0.0053,  0.0024,  0.0030,  0.0165, -0.0128, -0.0310],\n",
       "                      [-0.0038, -0.0126, -0.0060,  0.0026,  0.0458,  0.0075],\n",
       "                      [-0.0277,  0.0109,  0.0220,  0.0009, -0.0045, -0.0046],\n",
       "                      [-0.0045,  0.0122, -0.0205,  0.0004, -0.0311,  0.0110]])),\n",
       "             ('embeds.8.weight',\n",
       "              tensor([[-0.0003,  0.0077, -0.0186,  0.0048],\n",
       "                      [-0.0387,  0.0062, -0.0063,  0.0212],\n",
       "                      [-0.0502, -0.0310,  0.0525,  0.0237],\n",
       "                      [ 0.0522,  0.0250, -0.0130, -0.0052],\n",
       "                      [ 0.0258,  0.0264, -0.0304, -0.0059],\n",
       "                      [ 0.0296,  0.0376, -0.0234, -0.0346]])),\n",
       "             ('embeds.9.weight',\n",
       "              tensor([[ 0.0055,  0.0014, -0.0067],\n",
       "                      [-0.0409,  0.0161,  0.0067],\n",
       "                      [-0.0195,  0.0090, -0.0170],\n",
       "                      [ 0.0067,  0.0052, -0.0075]])),\n",
       "             ('bn_cont.weight',\n",
       "              tensor([0.9896, 1.0323, 0.9905, 0.9865, 0.9928, 0.9934, 1.0065, 0.9968, 0.9982,\n",
       "                      0.9854])),\n",
       "             ('bn_cont.bias',\n",
       "              tensor([ 0.0078, -0.0088, -0.0053,  0.0007, -0.0030, -0.0017, -0.0003,  0.0028,\n",
       "                       0.0061, -0.0049])),\n",
       "             ('bn_cont.running_mean',\n",
       "              tensor([ 0.0037,  0.0036,  0.0034,  0.0037,  0.0038, -0.0014,  0.0002,  0.0017,\n",
       "                      -0.0044, -0.0016])),\n",
       "             ('bn_cont.running_var',\n",
       "              tensor([1.0025, 1.0112, 1.0255, 0.9914, 1.0111, 0.9977, 1.0045, 0.9999, 1.0040,\n",
       "                      0.9991])),\n",
       "             ('bn_cont.num_batches_tracked', tensor(152)),\n",
       "             ('layers.0.0.weight',\n",
       "              tensor([[-0.1073, -0.1244, -0.0460,  ...,  0.0701, -0.1311, -0.0935],\n",
       "                      [ 0.0939,  0.1367,  0.1178,  ...,  0.0373,  0.1115, -0.0702],\n",
       "                      [-0.0257, -0.0878,  0.1400,  ..., -0.0672, -0.0216,  0.1248],\n",
       "                      ...,\n",
       "                      [ 0.0077, -0.0785, -0.0315,  ...,  0.1141, -0.0662,  0.0287],\n",
       "                      [-0.1093, -0.0892,  0.0054,  ..., -0.1289,  0.0235,  0.0792],\n",
       "                      [-0.0845,  0.1203,  0.0696,  ..., -0.0819,  0.0525,  0.1061]])),\n",
       "             ('layers.0.2.weight',\n",
       "              tensor([1.0013, 1.0078, 1.0016, 1.0043, 1.0024, 0.9937, 1.0023, 1.0010, 0.9988,\n",
       "                      1.0094, 1.0027, 0.9960, 1.0006, 1.0049, 0.9940, 1.0014, 0.9960, 0.9999,\n",
       "                      1.0060, 1.0151, 1.0016, 0.9976, 0.9955, 1.0005, 0.9986, 1.0018, 0.9901,\n",
       "                      1.0171, 0.9896, 0.9972, 1.0096, 0.9969, 0.9906, 0.9971, 1.0046, 1.0013,\n",
       "                      0.9915, 0.9980, 0.9918, 1.0105, 1.0021, 1.0003, 1.0000, 1.0068, 0.9945,\n",
       "                      1.0019, 0.9963, 1.0035, 1.0021, 1.0114, 0.9916, 1.0046, 1.0019, 1.0209,\n",
       "                      1.0103, 0.9995, 0.9955, 0.9878, 0.9963, 1.0070, 0.9929, 0.9910, 1.0021,\n",
       "                      0.9994, 1.0168, 1.0049, 0.9973, 0.9922, 1.0092, 1.0015, 0.9930, 0.9992,\n",
       "                      0.9863, 1.0096, 0.9990, 0.9979, 1.0057, 0.9993, 0.9961, 1.0127, 0.9994,\n",
       "                      0.9964, 0.9986, 0.9966, 0.9919, 1.0050, 0.9972, 1.0160, 0.9992, 0.9898,\n",
       "                      1.0082, 1.0038, 1.0068, 0.9983, 1.0064, 0.9947, 0.9957, 1.0077, 1.0030,\n",
       "                      1.0017, 1.0064, 0.9991, 0.9889, 1.0033, 0.9943, 0.9941, 0.9988, 1.0009,\n",
       "                      0.9909, 0.9955, 0.9953, 1.0026, 0.9982, 1.0114, 1.0015, 0.9839, 0.9999,\n",
       "                      1.0020, 0.9963, 0.9944, 0.9895, 0.9952, 1.0039, 0.9968, 1.0005, 0.9973,\n",
       "                      1.0124, 1.0054, 0.9918, 0.9932, 1.0027, 1.0030, 1.0002, 0.9946, 1.0062,\n",
       "                      1.0023, 0.9989, 1.0100, 0.9977, 1.0019, 1.0020, 1.0017, 1.0020, 0.9984,\n",
       "                      0.9989, 1.0064, 1.0017, 0.9972, 0.9963, 0.9943, 0.9862, 0.9974, 0.9879,\n",
       "                      1.0026, 1.0099, 0.9982, 0.9961, 1.0047, 0.9948, 0.9967, 0.9995, 0.9969,\n",
       "                      1.0112, 0.9959, 0.9982, 1.0027, 0.9866, 1.0149, 0.9991, 0.9914, 0.9957,\n",
       "                      0.9999, 1.0021, 1.0013, 1.0126, 1.0083, 0.9970, 0.9890, 1.0090, 1.0089,\n",
       "                      1.0007, 0.9979, 0.9939, 0.9961, 0.9945, 1.0043, 0.9897, 0.9941, 0.9963,\n",
       "                      0.9896, 1.0175, 0.9957, 1.0065, 0.9978, 1.0097, 1.0007, 0.9964, 1.0066,\n",
       "                      0.9869, 0.9961])),\n",
       "             ('layers.0.2.bias',\n",
       "              tensor([ 2.3367e-03, -8.1496e-04,  5.8449e-04,  8.7268e-03, -5.2683e-03,\n",
       "                       9.9949e-03,  5.8450e-03, -3.2215e-03, -3.9156e-03, -8.9285e-04,\n",
       "                      -1.3553e-03,  7.7123e-03,  4.6386e-03, -4.0358e-03, -2.4853e-03,\n",
       "                       4.4981e-03,  1.2103e-02, -3.8246e-03, -3.2299e-04, -5.3549e-03,\n",
       "                      -6.6777e-03, -1.1965e-03,  1.1763e-02, -1.3354e-04,  3.6870e-03,\n",
       "                      -1.9015e-03,  6.4266e-03,  1.5832e-02, -6.0074e-03, -3.6771e-03,\n",
       "                      -5.7463e-03,  2.9210e-03, -7.1926e-03, -1.4148e-03,  1.2773e-03,\n",
       "                      -4.9858e-03,  1.5642e-02, -5.8242e-03, -1.5728e-03,  1.1478e-02,\n",
       "                      -8.8529e-04, -3.2425e-03,  3.9882e-03, -1.2283e-02,  3.7710e-03,\n",
       "                      -7.3904e-03, -7.2793e-03, -1.2316e-03, -2.5346e-03, -2.0363e-03,\n",
       "                      -4.2794e-04,  1.6657e-02,  1.0297e-02, -3.0537e-03, -1.3076e-02,\n",
       "                       8.5215e-03, -1.1129e-02,  8.5366e-03, -1.4401e-03,  6.2920e-05,\n",
       "                      -1.1835e-03, -8.4784e-03, -6.4215e-03,  4.9652e-03,  1.0266e-02,\n",
       "                      -5.1010e-03, -3.4078e-05, -1.6223e-02,  1.0566e-03,  7.1367e-03,\n",
       "                      -5.9524e-03, -8.0185e-03, -2.2579e-03,  2.8962e-03, -5.4580e-03,\n",
       "                       5.7816e-03, -1.2710e-02,  7.8627e-03,  1.0463e-02, -6.2025e-03,\n",
       "                      -1.4154e-03,  7.7323e-03,  2.5723e-04,  6.1000e-03,  1.9955e-02,\n",
       "                       4.5979e-03, -3.3691e-03,  5.6730e-03,  3.1825e-04,  2.4555e-03,\n",
       "                       1.1588e-02, -1.2884e-02,  4.8481e-03,  1.9790e-03, -4.1376e-03,\n",
       "                      -1.3280e-02,  2.7958e-03, -9.3410e-03, -1.0478e-02, -2.0004e-03,\n",
       "                       8.1328e-03,  2.5202e-03, -6.0809e-03,  2.3338e-03,  2.4866e-03,\n",
       "                       1.4950e-02, -8.8177e-03, -1.3920e-04, -6.7750e-03, -3.8181e-03,\n",
       "                       5.6872e-04, -6.2650e-03,  4.2588e-03,  4.0093e-03,  9.6639e-03,\n",
       "                      -6.7420e-03,  3.8890e-03,  5.4768e-03, -1.4168e-03, -2.3101e-03,\n",
       "                       1.2451e-02, -1.7500e-03,  1.0759e-02, -1.3778e-03,  8.2098e-03,\n",
       "                      -2.6695e-03, -9.9950e-04, -1.7866e-03,  9.2349e-03,  1.0918e-02,\n",
       "                       6.0780e-04, -3.7738e-03,  1.0555e-02,  2.0820e-02, -2.8251e-03,\n",
       "                       1.8083e-03,  8.6258e-03,  1.4525e-02, -9.6017e-03,  6.3622e-03,\n",
       "                      -6.1275e-03, -8.9220e-05, -6.0011e-03, -1.3586e-02, -2.1125e-03,\n",
       "                      -2.5662e-03,  4.4581e-03, -1.5094e-02,  2.2598e-03, -5.7697e-04,\n",
       "                       1.2087e-02, -1.2465e-02, -4.6390e-03,  6.4217e-04,  5.5080e-03,\n",
       "                      -4.8929e-03,  2.7145e-04,  6.4302e-03, -1.2889e-03,  1.0568e-02,\n",
       "                      -3.1746e-03,  9.5868e-03,  1.0494e-02,  6.2071e-03,  6.4618e-03,\n",
       "                       7.3081e-03, -3.8990e-03, -1.9727e-03, -3.0504e-03, -9.7984e-03,\n",
       "                      -4.9126e-03, -6.2061e-03,  6.7333e-03,  1.8074e-02,  7.3734e-03,\n",
       "                      -2.1277e-03, -1.2803e-02, -6.3277e-03,  2.3953e-03,  1.1733e-02,\n",
       "                       1.2309e-02, -7.5656e-03,  8.3770e-03, -4.7919e-03, -6.0934e-03,\n",
       "                       1.0018e-04, -3.2726e-03,  3.6031e-03,  3.1793e-03,  2.6062e-03,\n",
       "                       7.7479e-04, -5.6874e-04, -3.2859e-03,  4.5177e-03, -4.4795e-03,\n",
       "                       1.1079e-02,  7.9161e-03,  6.2632e-03,  6.9728e-03,  1.8383e-02])),\n",
       "             ('layers.0.2.running_mean',\n",
       "              tensor([0.1451, 0.0749, 0.1296, 0.0715, 0.1325, 0.1024, 0.0982, 0.1070, 0.0740,\n",
       "                      0.0800, 0.0797, 0.1249, 0.0805, 0.0475, 0.0787, 0.0737, 0.1293, 0.1080,\n",
       "                      0.0917, 0.0853, 0.1299, 0.0520, 0.0815, 0.0454, 0.0723, 0.1591, 0.0915,\n",
       "                      0.0990, 0.0887, 0.1607, 0.0441, 0.1101, 0.1056, 0.0718, 0.0939, 0.0890,\n",
       "                      0.0953, 0.0855, 0.0931, 0.0731, 0.0760, 0.1435, 0.0758, 0.0623, 0.0807,\n",
       "                      0.1010, 0.1189, 0.1141, 0.1068, 0.0845, 0.0947, 0.1322, 0.0632, 0.0975,\n",
       "                      0.1115, 0.1525, 0.0869, 0.1040, 0.0774, 0.1091, 0.0886, 0.1263, 0.0662,\n",
       "                      0.0932, 0.0926, 0.0733, 0.1713, 0.1262, 0.0855, 0.1066, 0.0957, 0.0851,\n",
       "                      0.1247, 0.1433, 0.0801, 0.0741, 0.0405, 0.1339, 0.1141, 0.0761, 0.0978,\n",
       "                      0.1159, 0.1003, 0.0549, 0.1010, 0.0938, 0.0881, 0.0935, 0.1045, 0.0906,\n",
       "                      0.0579, 0.0734, 0.0980, 0.0834, 0.0621, 0.0993, 0.0910, 0.1066, 0.0716,\n",
       "                      0.1013, 0.0754, 0.1117, 0.1245, 0.0989, 0.0974, 0.0743, 0.0785, 0.1030,\n",
       "                      0.0869, 0.0946, 0.0816, 0.0801, 0.0552, 0.0899, 0.0671, 0.1558, 0.0950,\n",
       "                      0.1641, 0.0826, 0.1109, 0.1401, 0.1267, 0.1302, 0.0764, 0.0524, 0.1250,\n",
       "                      0.0769, 0.0768, 0.0958, 0.0772, 0.0880, 0.0917, 0.0695, 0.0509, 0.0620,\n",
       "                      0.1102, 0.0559, 0.0904, 0.1121, 0.0980, 0.0745, 0.0842, 0.0929, 0.0741,\n",
       "                      0.0573, 0.0590, 0.0936, 0.1173, 0.0370, 0.0810, 0.0749, 0.0888, 0.0831,\n",
       "                      0.1139, 0.0829, 0.0781, 0.0859, 0.0872, 0.0816, 0.1165, 0.0788, 0.1293,\n",
       "                      0.0755, 0.0951, 0.0937, 0.0900, 0.0852, 0.0677, 0.1257, 0.0834, 0.1173,\n",
       "                      0.0555, 0.0684, 0.0645, 0.0699, 0.0382, 0.0891, 0.0709, 0.0790, 0.1032,\n",
       "                      0.0940, 0.1180, 0.0876, 0.1137, 0.0874, 0.0663, 0.1483, 0.1050, 0.0915,\n",
       "                      0.1236, 0.0773, 0.0923, 0.0930, 0.0654, 0.1011, 0.1212, 0.1182, 0.1057,\n",
       "                      0.0901, 0.1442])),\n",
       "             ('layers.0.2.running_var',\n",
       "              tensor([0.0618, 0.0185, 0.0186, 0.0059, 0.0458, 0.0315, 0.0280, 0.0156, 0.0068,\n",
       "                      0.0148, 0.0182, 0.0499, 0.0237, 0.0092, 0.0221, 0.0195, 0.0194, 0.0347,\n",
       "                      0.0223, 0.0183, 0.0170, 0.0046, 0.0203, 0.0038, 0.0094, 0.0374, 0.0122,\n",
       "                      0.0163, 0.0139, 0.0625, 0.0076, 0.0319, 0.0269, 0.0184, 0.0148, 0.0289,\n",
       "                      0.0167, 0.0195, 0.0175, 0.0125, 0.0151, 0.0618, 0.0137, 0.0120, 0.0286,\n",
       "                      0.0248, 0.0537, 0.0259, 0.0297, 0.0240, 0.0175, 0.0219, 0.0094, 0.0257,\n",
       "                      0.0179, 0.0550, 0.0189, 0.0311, 0.0169, 0.0314, 0.0161, 0.0602, 0.0114,\n",
       "                      0.0215, 0.0103, 0.0150, 0.0300, 0.0413, 0.0248, 0.0240, 0.0237, 0.0249,\n",
       "                      0.0169, 0.0484, 0.0204, 0.0099, 0.0032, 0.0549, 0.0214, 0.0108, 0.0310,\n",
       "                      0.0430, 0.0217, 0.0133, 0.0152, 0.0331, 0.0136, 0.0220, 0.0340, 0.0342,\n",
       "                      0.0089, 0.0269, 0.0288, 0.0275, 0.0119, 0.0301, 0.0218, 0.0219, 0.0085,\n",
       "                      0.0313, 0.0133, 0.0499, 0.0634, 0.0244, 0.0282, 0.0184, 0.0198, 0.0285,\n",
       "                      0.0170, 0.0236, 0.0215, 0.0208, 0.0078, 0.0108, 0.0171, 0.0784, 0.0317,\n",
       "                      0.0279, 0.0181, 0.0139, 0.0221, 0.0246, 0.0577, 0.0090, 0.0048, 0.0183,\n",
       "                      0.0114, 0.0189, 0.0227, 0.0074, 0.0228, 0.0316, 0.0117, 0.0069, 0.0072,\n",
       "                      0.0541, 0.0047, 0.0121, 0.0275, 0.0214, 0.0197, 0.0120, 0.0299, 0.0189,\n",
       "                      0.0136, 0.0119, 0.0099, 0.0398, 0.0025, 0.0177, 0.0113, 0.0241, 0.0180,\n",
       "                      0.0346, 0.0083, 0.0241, 0.0333, 0.0195, 0.0140, 0.0255, 0.0050, 0.0159,\n",
       "                      0.0143, 0.0161, 0.0229, 0.0235, 0.0235, 0.0167, 0.0232, 0.0087, 0.0397,\n",
       "                      0.0122, 0.0085, 0.0055, 0.0144, 0.0023, 0.0225, 0.0108, 0.0167, 0.0122,\n",
       "                      0.0178, 0.0153, 0.0217, 0.0415, 0.0211, 0.0104, 0.0220, 0.0295, 0.0085,\n",
       "                      0.0648, 0.0116, 0.0233, 0.0242, 0.0077, 0.0318, 0.0398, 0.0189, 0.0316,\n",
       "                      0.0107, 0.0232])),\n",
       "             ('layers.0.2.num_batches_tracked', tensor(152)),\n",
       "             ('layers.1.0.weight',\n",
       "              tensor([[ 0.0479,  0.0528,  0.0530,  ..., -0.0239,  0.0373, -0.0261],\n",
       "                      [-0.0264, -0.0222, -0.0476,  ..., -0.0676, -0.0032, -0.0681],\n",
       "                      [-0.0235,  0.0509,  0.0074,  ...,  0.0496, -0.0623,  0.0512],\n",
       "                      ...,\n",
       "                      [-0.0285,  0.0459, -0.0496,  ...,  0.0234,  0.0460,  0.0307],\n",
       "                      [-0.0275,  0.0416,  0.0436,  ...,  0.0500, -0.0468, -0.0193],\n",
       "                      [ 0.0555,  0.0706,  0.0205,  ...,  0.0074,  0.0473, -0.0204]])),\n",
       "             ('layers.1.2.weight',\n",
       "              tensor([0.9945, 1.0069, 0.9980, 0.9957, 1.0046, 0.9938, 0.9930, 1.0006, 0.9908,\n",
       "                      0.9904, 0.9922, 1.0033, 1.0019, 0.9957, 0.9954, 0.9897, 0.9983, 0.9953,\n",
       "                      1.0010, 0.9924, 1.0067, 0.9923, 0.9936, 1.0055, 1.0063, 0.9992, 0.9973,\n",
       "                      0.9928, 0.9976, 1.0024, 0.9857, 0.9924, 0.9959, 0.9943, 0.9973, 0.9980,\n",
       "                      0.9999, 0.9931, 0.9923, 1.0001, 0.9909, 0.9959, 0.9986, 0.9946, 0.9997,\n",
       "                      1.0043, 0.9966, 0.9974, 0.9926, 0.9923, 0.9933, 1.0033, 0.9920, 1.0037,\n",
       "                      0.9954, 1.0072, 0.9882, 0.9912, 0.9975, 0.9892, 0.9928, 0.9973, 1.0077,\n",
       "                      0.9942, 0.9931, 0.9911, 0.9920, 0.9997, 0.9983, 1.0042, 1.0013, 0.9947,\n",
       "                      0.9927, 0.9997, 0.9961, 0.9963, 0.9944, 0.9994, 0.9965, 0.9921, 1.0047,\n",
       "                      0.9970, 1.0059, 1.0000, 0.9909, 1.0053, 0.9967, 0.9875, 0.9958, 0.9898,\n",
       "                      1.0003, 1.0031, 0.9985, 0.9948, 0.9999, 0.9971, 0.9929, 1.0002, 0.9842,\n",
       "                      1.0002])),\n",
       "             ('layers.1.2.bias',\n",
       "              tensor([-0.0784,  0.0674, -0.0629,  0.0680, -0.0631, -0.0595,  0.0638,  0.0667,\n",
       "                       0.0662, -0.0561,  0.0766, -0.0633,  0.0644, -0.0652,  0.0629, -0.0597,\n",
       "                       0.0668,  0.0629,  0.0974,  0.0629, -0.0650, -0.0588,  0.0642, -0.0635,\n",
       "                      -0.0634,  0.0729,  0.0659, -0.0591,  0.0718, -0.0666, -0.0250, -0.0576,\n",
       "                       0.0677, -0.0694,  0.0644, -0.0635,  0.0736, -0.0833, -0.0600,  0.0653,\n",
       "                       0.0615,  0.0637,  0.0653,  0.0641,  0.0959, -0.0710,  0.0635,  0.0897,\n",
       "                       0.0609,  0.0630, -0.0597,  0.0662,  0.0624, -0.0743,  0.0629, -0.0682,\n",
       "                       0.0615,  0.0946,  0.0648, -0.0591,  0.0594,  0.0673,  0.0711,  0.0626,\n",
       "                      -0.0617,  0.0612, -0.0612,  0.0659, -0.0638,  0.0645, -0.0862,  0.0785,\n",
       "                       0.0621, -0.0621,  0.0633,  0.0664,  0.0617, -0.0723,  0.0642, -0.0225,\n",
       "                      -0.0648, -0.0655, -0.0716,  0.0672,  0.0740, -0.0679,  0.0736,  0.0657,\n",
       "                      -0.0613,  0.0615,  0.0907, -0.0647, -0.0620, -0.0605,  0.0641, -0.0745,\n",
       "                       0.0796,  0.0839, -0.0769, -0.0623])),\n",
       "             ('layers.1.2.running_mean',\n",
       "              tensor([0.2125, 0.1330, 0.3431, 0.3389, 0.2102, 0.2748, 0.2268, 0.2120, 0.2760,\n",
       "                      0.2654, 0.2503, 0.1753, 0.3549, 0.2475, 0.2393, 0.2028, 0.2362, 0.2901,\n",
       "                      0.1972, 0.2708, 0.2432, 0.3518, 0.2747, 0.1846, 0.3089, 0.4631, 0.2618,\n",
       "                      0.3233, 0.3582, 0.2308, 0.1524, 0.1978, 0.2388, 0.2291, 0.2504, 0.2578,\n",
       "                      0.2118, 0.3783, 0.3737, 0.4198, 0.2646, 0.2809, 0.2449, 0.3261, 0.2920,\n",
       "                      0.1914, 0.3132, 0.2944, 0.3110, 0.2409, 0.2493, 0.3962, 0.3266, 0.2095,\n",
       "                      0.3642, 0.2351, 0.2826, 0.4059, 0.2425, 0.1919, 0.1838, 0.2768, 0.2221,\n",
       "                      0.1627, 0.3985, 0.2648, 0.2197, 0.2036, 0.2991, 0.2499, 0.1739, 0.2724,\n",
       "                      0.2574, 0.2239, 0.1841, 0.2707, 0.2188, 0.2789, 0.1953, 0.2638, 0.2325,\n",
       "                      0.2129, 0.1456, 0.3902, 0.2472, 0.2124, 0.4947, 0.2443, 0.1881, 0.3062,\n",
       "                      0.3050, 0.2256, 0.2245, 0.3083, 0.2345, 0.2387, 0.2780, 0.3014, 0.3691,\n",
       "                      0.1943])),\n",
       "             ('layers.1.2.running_var',\n",
       "              tensor([0.1068, 0.0331, 0.4347, 0.1326, 0.1355, 0.2908, 0.0827, 0.1082, 0.1109,\n",
       "                      0.1639, 0.1477, 0.1022, 0.1202, 0.1277, 0.2040, 0.1120, 0.1982, 0.3170,\n",
       "                      0.1243, 0.1216, 0.1529, 0.3671, 0.1498, 0.0870, 0.2758, 0.2423, 0.2427,\n",
       "                      0.3346, 0.1542, 0.1383, 0.0897, 0.1476, 0.1999, 0.0839, 0.0894, 0.1632,\n",
       "                      0.1458, 0.4445, 0.3727, 0.4251, 0.1015, 0.2214, 0.1587, 0.2933, 0.0838,\n",
       "                      0.0966, 0.2753, 0.2695, 0.2121, 0.1953, 0.1612, 0.1440, 0.1111, 0.0778,\n",
       "                      0.1350, 0.1963, 0.1882, 0.4927, 0.1212, 0.1358, 0.1075, 0.1046, 0.0986,\n",
       "                      0.0906, 0.2724, 0.0862, 0.1331, 0.1032, 0.2327, 0.1911, 0.1017, 0.1136,\n",
       "                      0.1116, 0.1417, 0.0857, 0.2084, 0.0723, 0.1925, 0.1045, 0.0984, 0.1841,\n",
       "                      0.1454, 0.0459, 0.1348, 0.2301, 0.0910, 0.2992, 0.1634, 0.1157, 0.3093,\n",
       "                      0.1122, 0.1404, 0.1416, 0.3784, 0.1210, 0.1244, 0.1557, 0.2010, 0.3999,\n",
       "                      0.1192])),\n",
       "             ('layers.1.2.num_batches_tracked', tensor(152)),\n",
       "             ('layers.2.0.weight',\n",
       "              tensor([[-0.0532,  0.0976,  0.0043,  0.0771, -0.1068, -0.0823, -0.0495, -0.0036,\n",
       "                        0.0339, -0.0846,  0.0302, -0.1035,  0.0388,  0.0004,  0.0994, -0.0818,\n",
       "                        0.1122,  0.0350,  0.0829,  0.0999, -0.1010,  0.0192,  0.0031, -0.1018,\n",
       "                       -0.0968,  0.1085,  0.0955, -0.0195,  0.0518, -0.0769, -0.0602,  0.0187,\n",
       "                        0.0478, -0.0905,  0.0986, -0.0213,  0.0540, -0.0730, -0.0249,  0.0668,\n",
       "                        0.0312, -0.0157,  0.0325,  0.0992,  0.0153, -0.0971,  0.0364,  0.0485,\n",
       "                        0.0913,  0.0632, -0.0006,  0.1090,  0.0865, -0.0574,  0.1032,  0.0236,\n",
       "                        0.0265, -0.0597,  0.0044, -0.0735, -0.0371,  0.0734, -0.0098,  0.0706,\n",
       "                       -0.0918,  0.1023, -0.1015,  0.0869, -0.0507,  0.1073,  0.0305,  0.0054,\n",
       "                        0.0771, -0.0725,  0.1041,  0.0551,  0.1042,  0.0630,  0.0664, -0.0902,\n",
       "                       -0.0950, -0.0255, -0.0017,  0.0792,  0.0732, -0.0120, -0.0044, -0.0448,\n",
       "                       -0.0806,  0.0964,  0.0583, -0.0110, -0.0937, -0.0766,  0.0175, -0.0289,\n",
       "                        0.0405,  0.0375,  0.0664, -0.0910],\n",
       "                      [-0.0144, -0.0618,  0.0414,  0.0426,  0.0313,  0.0167, -0.0995, -0.1119,\n",
       "                       -0.0039, -0.0167, -0.0026,  0.0357, -0.0964,  0.0757, -0.0326,  0.0833,\n",
       "                        0.0256, -0.0998,  0.0313,  0.0335,  0.0286,  0.0774, -0.0759,  0.0919,\n",
       "                        0.0570,  0.0700,  0.0230,  0.0705,  0.0144,  0.0320, -0.0532,  0.0666,\n",
       "                       -0.0179, -0.0611, -0.1040,  0.0979, -0.0157, -0.0461,  0.0665, -0.0633,\n",
       "                       -0.0671, -0.0742, -0.0643,  0.0657, -0.0254, -0.0292, -0.0677,  0.0079,\n",
       "                        0.0346, -0.0861,  0.0903,  0.0094, -0.0884,  0.0082, -0.0545,  0.1059,\n",
       "                       -0.0981, -0.0948, -0.0874,  0.0847, -0.0656, -0.0087, -0.1097, -0.0340,\n",
       "                       -0.0182, -0.0047, -0.0154, -0.0180,  0.0471, -0.0980,  0.0763, -0.0351,\n",
       "                       -0.0762,  0.0924, -0.0411, -0.0119,  0.0559,  0.1051, -0.0174, -0.0828,\n",
       "                        0.0098,  0.0431,  0.0660, -0.0026,  0.0549,  0.0627, -0.0368, -0.0650,\n",
       "                        0.0642, -0.0796,  0.0158,  0.0774,  0.0497,  0.1007, -0.0864,  0.0225,\n",
       "                        0.0104, -0.0083,  0.0870,  0.1114]])),\n",
       "             ('layers.2.0.bias', tensor([ 0.1266, -0.0036]))])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learnC.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5eb95d6a783051f7e4f7c764ada467adc5d084fb79225f5dbfbb6f693fbec43"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('fastenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
