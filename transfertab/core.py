# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/01_transfer.ipynb (unless otherwise specified).

__all__ = ['TabTransfer']

# Cell
class TabTransfer:
    def __init__(self, old_learner, new_learner):
        self.old_cat_names = old_learner.dls.cat_names
        self.old_all_classes = old_learner.dls.classes
        self.old_learner = old_learner

        self.new_cat_names = new_learner.dls.cat_names
        self.new_all_classes = new_learner.dls.classes
        self.new_learner = new_learner


    def transfer(self, cat_names_to_transfer, verbose=False):
        self.transfer_list = cat_names_to_transfer
        for curr_cat in self.transfer_list:
            if not (curr_cat in self.old_cat_names and curr_cat in self.new_cat_names):
                continue
            old_cat_idx = self.old_cat_names.index(curr_cat)
            new_cat_idx = self.new_cat_names.index(curr_cat)



            # TODO: Make it so that this isn't required by taking care of this.
            try: assert (self.old_learner.model.embeds[old_cat_idx].embedding_dim == self.new_learner.model.embeds[new_cat_idx].embedding_dim)
            except:
                print(f"Encountered an error for variable {curr_cat}: Make sure embeddings dimensions are same for {self.old_learner.model.embeds[old_cat_idx]} and {self.new_learner.model.embeds[new_cat_idx]}")
                print("Moving on to other cat vars")
                continue

            old_curr_classes = self.old_all_classes[curr_cat]
            new_curr_classes = self.new_all_classes[curr_cat]
            global temp
            temp = new_curr_classes
#             if old_curr_classes<new_curr_classes:
#                 sitch = 1
#             else if old_curr_classes=new_curr_classes:
#                 sitch = 2
#             else if old_curr_classes<new_curr_classes:
#                 sitch = 3

            weights_mean = self.old_learner.model.embeds[old_cat_idx].weight.mean(0)
            if verbose: print(f'mean is {weights_mean} for {self.old_learner.model.embeds[old_cat_idx].weight}')

#             switch(sitch):
#                 case 1:

            # Case where some category in old, but not in new isn't being handled rn.

            for new_curr_class in new_curr_classes:
                new_curr_class_idx = new_curr_classes.o2i[new_curr_class]
                if verbose: print(f"{new_curr_class_idx}, {type(new_curr_class_idx)}")

                if new_curr_class in old_curr_classes:
                    old_curr_class_idx = old_curr_classes.o2i[new_curr_class]
                    if verbose: print(f'Transferring weights for class {new_curr_class}, cat {curr_cat} from previous weights')
                    if verbose: print(f"old weight for class is {self.new_learner.model.embeds[new_cat_idx].weight[new_curr_class_idx, :]}")
                    tempwgt1 = self.new_learner.model.embeds[new_cat_idx].weight[new_curr_class_idx, :]
                    tempwgt2 = self.old_learner.model.embeds[old_cat_idx].weight[old_curr_class_idx, :]
                    self.new_learner.model.embeds[new_cat_idx].weight.data[new_curr_class_idx, :] = self.old_learner.model.embeds[old_cat_idx].weight[old_curr_class_idx, :].detach().clone()
                    self.new_learner.model.embeds[new_cat_idx].weight[new_curr_class_idx, :].required_grad = True
                    if verbose: print(f"new weight for class is {self.new_learner.model.embeds[new_cat_idx].weight[new_curr_class_idx, :]}")
                else:
                    if verbose: print(f'Transferring weights for class {new_curr_class}, cat {curr_cat} using mean')
                    if verbose: print(f"old weight for class is {self.new_learner.model.embeds[new_cat_idx].weight[new_curr_class_idx, :]}")
                    self.new_learner.model.embeds[new_cat_idx].weight.data[new_curr_class_idx, :] = weights_mean
                    self.new_learner.model.embeds[new_cat_idx].weight[new_curr_class_idx, :].required_grad = True
                    if verbose: print(f"new weight for class is {self.new_learner.model.embeds[new_cat_idx].weight[new_curr_class_idx, :]}")